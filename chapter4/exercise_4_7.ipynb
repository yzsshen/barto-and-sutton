{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4.7\n",
    "\n",
    "Write a program for policy iteration and re-solve Jack’s car rental problem with the following changes.\n",
    "\n",
    "One of Jack’s employees at the first location rides a bus home each night and lives near the second location. \n",
    "\n",
    "She is happy to shuttle one car to the second location for free. \n",
    "\n",
    "Each additional car still costs $2, as do all cars moved in the other direction. \n",
    "\n",
    "In addition, Jack has limited parking space at each location. \n",
    "\n",
    "If more than 10 cars are kept overnight at a location (after any moving of cars), then an additional cost of $4 must be incurred to use a second parking lot (independent of how many cars are kept there). \n",
    "\n",
    "These sorts of nonlinearities and arbitrary dynamics often occur in real problems and cannot easily be handled by optimization methods other than dynamic programming. To check your program, first replicate the results given for the original problem.\n",
    "\n",
    "![Jack's car rental problem](ex4.2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing_extensions import Self\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create State class\n",
    "@dataclass\n",
    "class State:\n",
    "    cars_loc1: int\n",
    "    cars_loc2: int\n",
    "    \n",
    "    def __hash__(self) -> int:\n",
    "        return hash((self.cars_loc1, self.cars_loc2))\n",
    "    \n",
    "    def __eq__(self, other) -> bool:\n",
    "        if not isinstance(other, State):\n",
    "            return False\n",
    "        return (self.cars_loc1 == other.cars_loc1 and \n",
    "                self.cars_loc2 == other.cars_loc2)\n",
    "    \n",
    "    def __post_init__(self) -> None:\n",
    "        if not (0 <= self.cars_loc1 <= 20 and 0 <= self.cars_loc2 <= 20):\n",
    "            raise ValueError(\"Cars at each location must be between 0 and 20\")\n",
    "        \n",
    "    def move_cars(self, cars_moved_l1_to_l2: int) -> tuple[Self, int]:\n",
    "        assert (-5 <= cars_moved_l1_to_l2 <= 5, \"Actions can only move up to 5 cars\")\n",
    "        assert (cars_moved_l1_to_l2 <= self.cars_loc1 and -cars_moved_l1_to_l2 <= self.cars_loc2), \"Cannot move more cars than there are at the location\")\n",
    "        \n",
    "        reward = -2 * np.abs(cars_moved_l1_to_l2)\n",
    "        \n",
    "        return State(\n",
    "            cars_loc1=self.cars_loc1-cars_moved_l1_to_l2, \n",
    "            cars_loc2=self.cars_loc2+cars_moved_l1_to_l2,\n",
    "            ), reward\n",
    "    \n",
    "    @staticmethod\n",
    "    def poisson_prob(n: int, lambda_: int) -> float:\n",
    "        return (lambda_**n / np.math.factorial(n)) * np.exp(-lambda_)\n",
    "\n",
    "    def rent_car(self, location: int, rented_cars: int) -> tuple[Self, float, int]:\n",
    "        match location:\n",
    "            case 1:\n",
    "                cars_available: int = self.cars_loc1\n",
    "            case 2:\n",
    "                cars_available:int = self.cars_loc2\n",
    "        \n",
    "        assert 0 <= rented_cars <= cars_available, \"Cannot rent more cars than are available\"\n",
    "        \n",
    "        reward = 10 * rented_cars\n",
    "        \n",
    "        match location:\n",
    "            case 1:\n",
    "                return State(\n",
    "                    cars_loc1=self.cars_loc1-rented_cars, \n",
    "                    cars_loc2=self.cars_loc2,\n",
    "                    )\n",
    "            case 2:\n",
    "                return State(\n",
    "                    cars_loc1=self.cars_loc1, \n",
    "                    cars_loc2=self.cars_loc2-rented_cars,\n",
    "                    )\n",
    "    \n",
    "    def return_car(self, location: int, returned_cars: int) -> tuple[Self, float]:\n",
    "        match location:\n",
    "            case 1:\n",
    "                cars_available: int = self.cars_loc1\n",
    "            case 2:\n",
    "                cars_available:int = self.cars_loc2\n",
    "        \n",
    "        assert 20 >= returned_cars + cars_available, \"Cannot have than 20 cars in parking lot\"\n",
    "        \n",
    "        match location:\n",
    "            case 1:\n",
    "                return State(\n",
    "                    cars_loc1=self.cars_loc1+returned_cars, \n",
    "                    cars_loc2=self.cars_loc2,\n",
    "                    )\n",
    "            case 2:\n",
    "                return State(\n",
    "                    cars_loc1=self.cars_loc1, \n",
    "                    cars_loc2=self.cars_loc2+returned_cars,\n",
    "                    )\n",
    "    \n",
    "    def get_all_transitions(self, action: int) -> list[tuple[Self, float, int]]:\n",
    "        \"\"\"\n",
    "        Returns list of (next_state, probability, reward) for all possible transitions\n",
    "        given an action.\n",
    "        \"\"\"\n",
    "        # 1. Move cars overnight\n",
    "        next_state, move_reward = self.move_cars(action)\n",
    "        \n",
    "        transitions = []\n",
    "        # 2. Iterate over all possible combinations:\n",
    "        for rentals_loc1 in range(min(next_state.cars_loc1+1)):\n",
    "            for returns_loc1 in range(21):\n",
    "                for rentals_loc2 in range(min(next_state.cars_loc2 + 1)):\n",
    "                    for returns_loc2 in range(21):\n",
    "                        if not (returns_loc1 - rentals_loc1 == next_state.cars_loc1 - (self.cars_loc1 - action)):\n",
    "                            continue\n",
    "                        elif not (returns_loc2 - rentals_loc2 == next_state.cars_loc2 - (self.cars_loc2 + action)):\n",
    "                            continue\n",
    "                        elif not (0 <= rentals_loc1 <= next_state.cars_loc1):\n",
    "                            continue\n",
    "                        elif not (0 <= rentals_loc2 <= next_state.cars_loc2):\n",
    "                            continue\n",
    "                        elif not (0 <= next_state.cars_loc1 - rentals_loc1 + returns_loc1 <= 20):\n",
    "                            continue\n",
    "                        elif not (0 <= next_state.cars_loc2 - rentals_loc2 + returns_loc2 <= 20):\n",
    "                            continue\n",
    "                        \n",
    "                        final_state = State(\n",
    "                            cars_loc1=next_state.cars_loc1 - rentals_loc1 + returns_loc1,\n",
    "                            cars_loc2=next_state.cars_loc2 - rentals_loc2 + returns_loc2\n",
    "                        )\n",
    "                        \n",
    "                        # Check if valid state\n",
    "                        try:\n",
    "                            final_state.__post_init__()\n",
    "                        except ValueError:\n",
    "                            continue\n",
    "                            \n",
    "                        # Calculate probabilities\n",
    "                        rent_loc1_prob: float = self.poisson_prob(rentals_loc1, 3)\n",
    "                        return_loc1_prob: float = self.poisson_prob(returns_loc1, 3)\n",
    "                        rent_loc2_prob: float = self.poisson_prob(rentals_loc2, 4)\n",
    "                        return_loc2_prob: float = self.poisson_prob(returns_loc2, 2)\n",
    "                        \n",
    "                        probability: float = rent_loc1_prob * return_loc1_prob * rent_loc2_prob * return_loc2_prob\n",
    "                        reward: int = move_reward + 10 * (rentals_loc1 + rentals_loc2)\n",
    "                        \n",
    "                        transitions.append((final_state, probability, reward))\n",
    "                        \n",
    "        return transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize\n",
    "def initialize() -> tuple[dict, dict]:\n",
    "    # Initialize V(s) and pi(s) arbitrarily for all s in S\n",
    "    V: dict[State, float] = {}\n",
    "    policy: dict[State, int] = {}\n",
    "    \n",
    "    # All possible states\n",
    "    for cars_loc1 in range(21):\n",
    "        for cars_loc2 in range(21):\n",
    "            state = State(cars_loc1, cars_loc2)\n",
    "            V[state] = 0 # arbitrary\n",
    "            policy[state] = 0 # don't move cars (arbitrary)\n",
    "    \n",
    "    return V, policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Policy Evaluation\n",
    "def policy_evaluation(V: dict, policy: dict, theta: float=0.01, gamma: float=0.9) -> tuple[dict, dict]:\n",
    "    while True:\n",
    "        delta = 0\n",
    "        # Loop through states\n",
    "        for state in V:\n",
    "            v = V[state]\n",
    "            \n",
    "            # Get transitions for current policy\n",
    "            transitions = state.get_all_transitions(policy[state])\n",
    "            \n",
    "            # Set new V based on update equation\n",
    "            V[state] = sum(prob * (reward + gamma * V[next_state]) for next_state, prob, reward in transitions)\n",
    "            \n",
    "            # Set Delta\n",
    "            delta = max(delta, np.abs(v - V[state]))\n",
    "            \n",
    "            # Check if Delta less than theta\n",
    "        if delta < theta:\n",
    "            break\n",
    "        \n",
    "    return V, policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Policy Improvement\n",
    "def policy_improvement(V: dict, policy: dict, gamma: float=0.9) -> tuple[dict, dict, bool]:\n",
    "    policy_stable = True\n",
    "    \n",
    "    # Loop through states\n",
    "    for state in V:\n",
    "        # Set old action\n",
    "        old_action = policy[state]\n",
    "        \n",
    "        # Calculate value under current policy\n",
    "        old_transitions = state.get_all_transitions(old_action)\n",
    "        current_value = sum(prob * (reward + gamma * V[next_state]) for next_state, prob, reward in old_transitions)\n",
    "        \n",
    "        # Find best action\n",
    "        best_value = float('-inf')\n",
    "        best_action = old_action\n",
    "        \n",
    "        for action in range(-5, 6):\n",
    "            try:\n",
    "                # Get all transitions for this action\n",
    "                transitions = state.get_all_transitions(action)\n",
    "            except AssertionError:\n",
    "                # Skip invalid actions\n",
    "                continue\n",
    "            \n",
    "                            \n",
    "            # Calculate value of the action\n",
    "            action_value = sum(prob * (reward + gamma * V[next_state]) for next_state, prob, reward in transitions)\n",
    "            \n",
    "            # Update if value is better\n",
    "            if action_value > best_value:\n",
    "                best_value = action_value\n",
    "                best_action = action\n",
    "            \n",
    "        # Update policy if there is a better action\n",
    "        if best_value > current_value:\n",
    "            policy[state] = best_action\n",
    "            if old_action != best_action:\n",
    "                policy_stable = False\n",
    "            \n",
    "    return V, policy, policy_stable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Policy Iteration Loop\n",
    "def policy_iteration(theta: float=0.01, gamma: float=0.9) -> tuple[dict, dict]:\n",
    "    # 1. Initialization\n",
    "    V, policy = initialize()\n",
    "    \n",
    "    while True:\n",
    "        # 2. Policy Evaluation\n",
    "        V, policy = policy_evaluation(V, policy, theta, gamma)\n",
    "        \n",
    "        # 3. Policy Improvement\n",
    "        V, policy, policy_stable = policy_improvement(V, policy, gamma)\n",
    "        \n",
    "        if policy_stable:\n",
    "            break\n",
    "        \n",
    "    return V, policy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
