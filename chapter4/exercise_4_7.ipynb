{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4.7\n",
    "\n",
    "Write a program for policy iteration and re-solve Jack’s car rental problem with the following changes.\n",
    "\n",
    "One of Jack’s employees at the first location rides a bus home each night and lives near the second location. \n",
    "\n",
    "She is happy to shuttle one car to the second location for free. \n",
    "\n",
    "Each additional car still costs $2, as do all cars moved in the other direction. \n",
    "\n",
    "In addition, Jack has limited parking space at each location. \n",
    "\n",
    "If more than 10 cars are kept overnight at a location (after any moving of cars), then an additional cost of $4 must be incurred to use a second parking lot (independent of how many cars are kept there). \n",
    "\n",
    "These sorts of nonlinearities and arbitrary dynamics often occur in real problems and cannot easily be handled by optimization methods other than dynamic programming. To check your program, first replicate the results given for the original problem.\n",
    "\n",
    "![Jack's car rental problem](ex4.2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing_extensions import Self\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "from scipy.stats import poisson\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create State class\n",
    "@dataclass\n",
    "class State:\n",
    "    cars_loc1: int\n",
    "    cars_loc2: int\n",
    "    \n",
    "    def __hash__(self) -> int:\n",
    "        return hash((self.cars_loc1, self.cars_loc2))\n",
    "    \n",
    "    def __eq__(self, other) -> bool:\n",
    "        if not isinstance(other, State):\n",
    "            return False\n",
    "        return (self.cars_loc1 == other.cars_loc1 and \n",
    "                self.cars_loc2 == other.cars_loc2)\n",
    "    \n",
    "    def __post_init__(self) -> None:\n",
    "        assert (0 <= self.cars_loc1 <= 20 and 0 <= self.cars_loc2 <= 20), \"Cars at each location must be between 0 and 20\"\n",
    "        \n",
    "    def move_cars(self, cars_moved_l1_to_l2: int) -> tuple[Self, int]:\n",
    "        assert (-5 <= cars_moved_l1_to_l2 <= 5), \"Actions can only move up to 5 cars\"\n",
    "        assert (cars_moved_l1_to_l2 <= self.cars_loc1 and -cars_moved_l1_to_l2 <= self.cars_loc2), \"Cannot move more cars than there are at the location\"\n",
    "        \n",
    "        reward = -2 * np.abs(cars_moved_l1_to_l2)\n",
    "        \n",
    "        return State(\n",
    "            cars_loc1=self.cars_loc1-cars_moved_l1_to_l2, \n",
    "            cars_loc2=self.cars_loc2+cars_moved_l1_to_l2,\n",
    "            ), reward\n",
    "    \n",
    "    @staticmethod\n",
    "    def poisson_prob(n: int, lambda_: int) -> float:\n",
    "        return (lambda_**n / math.factorial(n)) * np.exp(-lambda_)\n",
    "\n",
    "    def rent_car(self, location: int, rented_cars: int) -> tuple[Self, float, int]:\n",
    "        match location:\n",
    "            case 1:\n",
    "                cars_available: int = self.cars_loc1\n",
    "            case 2:\n",
    "                cars_available:int = self.cars_loc2\n",
    "        \n",
    "        assert 0 <= rented_cars <= cars_available, \"Cannot rent more cars than are available\"\n",
    "        \n",
    "        reward = 10 * rented_cars\n",
    "        \n",
    "        match location:\n",
    "            case 1:\n",
    "                return State(\n",
    "                    cars_loc1=self.cars_loc1-rented_cars, \n",
    "                    cars_loc2=self.cars_loc2,\n",
    "                    )\n",
    "            case 2:\n",
    "                return State(\n",
    "                    cars_loc1=self.cars_loc1, \n",
    "                    cars_loc2=self.cars_loc2-rented_cars,)\n",
    "    \n",
    "    def return_car(self, location: int, returned_cars: int) -> tuple[Self, float]:\n",
    "        match location:\n",
    "            case 1:\n",
    "                cars_available: int = self.cars_loc1\n",
    "            case 2:\n",
    "                cars_available:int = self.cars_loc2\n",
    "        \n",
    "        assert 20 >= returned_cars + cars_available, \"Cannot have than 20 cars in parking lot\"\n",
    "        \n",
    "        match location:\n",
    "            case 1:\n",
    "                return State(\n",
    "                    cars_loc1=self.cars_loc1+returned_cars, \n",
    "                    cars_loc2=self.cars_loc2,)\n",
    "            case 2:\n",
    "                return State(\n",
    "                    cars_loc1=self.cars_loc1, \n",
    "                    cars_loc2=self.cars_loc2+returned_cars,)\n",
    "    \n",
    "    def get_all_transitions(self, action: int) -> list[tuple[Self, float, int]]:\n",
    "        \"\"\"\n",
    "        Returns list of (next_state, probability, reward) for all possible transitions\n",
    "        given an action.\n",
    "        \"\"\"\n",
    "        # 1. Move cars overnight\n",
    "        next_state, move_reward = self.move_cars(action)\n",
    "        \n",
    "        transitions = []\n",
    "        # 2. Iterate over all possible combinations:\n",
    "        for rentals_loc1 in range(next_state.cars_loc1+1):\n",
    "            max_returns_loc1 = 20 - (next_state.cars_loc1 - rentals_loc1)\n",
    "            for returns_loc1 in range(max_returns_loc1 + 1):\n",
    "                for rentals_loc2 in range(next_state.cars_loc2 + 1):\n",
    "                    max_returns_loc2 = 20 - (next_state.cars_loc2 - rentals_loc2)\n",
    "                    for returns_loc2 in range(max_returns_loc2 + 1):\n",
    "                        if not (0 <= rentals_loc1 <= next_state.cars_loc1):\n",
    "                            continue\n",
    "                        elif not (0 <= rentals_loc2 <= next_state.cars_loc2):\n",
    "                            continue\n",
    "                        elif not (0 <= next_state.cars_loc1 - rentals_loc1 + returns_loc1 <= 20):\n",
    "                            continue\n",
    "                        elif not (0 <= next_state.cars_loc2 - rentals_loc2 + returns_loc2 <= 20):\n",
    "                            continue\n",
    "                        \n",
    "                        final_state = State(\n",
    "                            cars_loc1=next_state.cars_loc1 - rentals_loc1 + returns_loc1,\n",
    "                            cars_loc2=next_state.cars_loc2 - rentals_loc2 + returns_loc2,)\n",
    "                        \n",
    "                        # Check if valid state\n",
    "                        try:\n",
    "                            final_state.__post_init__()\n",
    "                        except ValueError:\n",
    "                            continue\n",
    "                            \n",
    "                        # Calculate probabilities\n",
    "                        rent_loc1_prob: float = self.poisson_prob(rentals_loc1, 3)\n",
    "                        return_loc1_prob: float = self.poisson_prob(returns_loc1, 3)\n",
    "                        rent_loc2_prob: float = self.poisson_prob(rentals_loc2, 4)\n",
    "                        return_loc2_prob: float = self.poisson_prob(returns_loc2, 2)\n",
    "                        \n",
    "                        probability: float = rent_loc1_prob * return_loc1_prob * rent_loc2_prob * return_loc2_prob\n",
    "                        reward: int = move_reward + 10 * (rentals_loc1 + rentals_loc2)\n",
    "                        \n",
    "                        transitions.append((final_state, probability, reward))\n",
    "                        \n",
    "        return transitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for Policy Iteration for original State class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize\n",
    "def initialize() -> tuple[dict, dict]:\n",
    "    # Initialize V(s) and pi(s) arbitrarily for all s in S\n",
    "    V: dict[State, float] = {}\n",
    "    policy: dict[State, int] = {}\n",
    "    \n",
    "    # All possible states\n",
    "    for cars_loc1 in range(21):\n",
    "        for cars_loc2 in range(21):\n",
    "            state = State(cars_loc1, cars_loc2)\n",
    "            V[state] = 0 # arbitrary\n",
    "            policy[state] = 0 # don't move cars (arbitrary)\n",
    "    \n",
    "    return V, policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Policy Evaluation\n",
    "def policy_evaluation(V: dict, policy: dict, theta: float=0.01, gamma: float=0.9) -> tuple[dict, dict]:\n",
    "    eval_iteration = 0\n",
    "    while True:\n",
    "        delta = 0\n",
    "        # Loop through states\n",
    "        for state in V:\n",
    "            v = V[state]\n",
    "            \n",
    "            # Get transitions for current policy\n",
    "            transitions = state.get_all_transitions(policy[state])\n",
    "            \n",
    "            # Set new V based on update equation\n",
    "            V[state] = sum(prob * (reward + gamma * V[next_state]) for next_state, prob, reward in transitions)\n",
    "            \n",
    "            # Set Delta\n",
    "            delta = max(delta, np.abs(v - V[state]))\n",
    "        \n",
    "        eval_iteration += 1\n",
    "        print(f\"Policy Evaluation iteration {eval_iteration}, delta: {delta}\")\n",
    "        \n",
    "        # Check if Delta less than theta\n",
    "        if delta < theta:\n",
    "            break\n",
    "        \n",
    "    return V, policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Policy Improvement\n",
    "def policy_improvement(V: dict, policy: dict, gamma: float=0.9) -> tuple[dict, dict, bool]:\n",
    "    policy_stable = True\n",
    "    action_changes = 0\n",
    "    \n",
    "    # Loop through states\n",
    "    for state in V:\n",
    "        # Set old action\n",
    "        old_action = policy[state]\n",
    "        \n",
    "        # Calculate value under current policy\n",
    "        old_transitions = state.get_all_transitions(old_action)\n",
    "        current_value = sum(prob * (reward + gamma * V[next_state]) for next_state, prob, reward in old_transitions)\n",
    "        \n",
    "        # Find best action\n",
    "        best_value = float('-inf')\n",
    "        best_action = old_action\n",
    "        \n",
    "        for action in range(-5, 6):\n",
    "            try:\n",
    "                # Get all transitions for this action\n",
    "                transitions = state.get_all_transitions(action)\n",
    "            except AssertionError:\n",
    "                # Skip invalid actions\n",
    "                continue\n",
    "            \n",
    "                            \n",
    "            # Calculate value of the action\n",
    "            action_value = sum(prob * (reward + gamma * V[next_state]) for next_state, prob, reward in transitions)\n",
    "            \n",
    "            # Update if value is better\n",
    "            if action_value > best_value:\n",
    "                best_value = action_value\n",
    "                best_action = action\n",
    "            \n",
    "        # Update policy if there is a better action\n",
    "        if best_value > current_value:\n",
    "            policy[state] = best_action\n",
    "            if old_action != best_action:\n",
    "                action_changes += 1\n",
    "                policy_stable = False\n",
    "    \n",
    "    print(f\"Number of policy changes: {action_changes}\")\n",
    "    return V, policy, policy_stable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_value_policy(V, policy):\n",
    "    # Create meshgrid of states\n",
    "    X, Y = np.meshgrid(range(21), range(21))\n",
    "    values = np.zeros((21, 21))\n",
    "    actions = np.zeros((21, 21))\n",
    "    \n",
    "    for i in range(21):\n",
    "        for j in range(21):\n",
    "            state = State(i, j)\n",
    "            values[i,j] = V[state]\n",
    "            actions[i,j] = policy[state]\n",
    "    \n",
    "    # Plot values\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    plt.subplot(121)\n",
    "    plt.imshow(values, origin='lower')\n",
    "    plt.colorbar(label='Value')\n",
    "    plt.title('State Values')\n",
    "    plt.xlabel('Cars at Location 2')\n",
    "    plt.ylabel('Cars at Location 1')\n",
    "    plt.xticks(range(0, 21, 5))\n",
    "    plt.yticks(range(0, 21, 5))\n",
    "    \n",
    "    # Plot policy\n",
    "    plt.subplot(122)\n",
    "    plt.imshow(actions, origin='lower')\n",
    "    plt.colorbar(label='Action')\n",
    "    plt.title('Policy (cars to move)')\n",
    "    plt.xlabel('Cars at Location 2')\n",
    "    plt.ylabel('Cars at Location 1')\n",
    "    plt.xticks(range(0, 21, 5))\n",
    "    plt.yticks(range(0, 21, 5))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Policy Iteration Loop\n",
    "def policy_iteration(theta: float=0.01, gamma: float=0.9) -> tuple[dict, dict]:\n",
    "    # 1. Initialization\n",
    "    V, policy = initialize()\n",
    "    iteration = 0\n",
    "    \n",
    "    while True:\n",
    "        iteration += 1\n",
    "        print(f\"Iteration {iteration}\")\n",
    "        \n",
    "        # 2. Policy Evaluation\n",
    "        print(f\"Policy Evaluation...\")\n",
    "        V, policy = policy_evaluation(V, policy, theta, gamma)\n",
    "        \n",
    "        # 3. Policy Improvement\n",
    "        print(f\"Policy Improvement...\")\n",
    "        V, policy, policy_stable = policy_improvement(V, policy, gamma)\n",
    "        \n",
    "        if policy_stable:\n",
    "            print(f'Policy is stable!')\n",
    "            break\n",
    "        \n",
    "    return V, policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Policy Iteration Sequential Run\n",
    "This took about 2 hours to run, so I will try to parallelize it by vectorizing our operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1\n",
      "Policy Evaluation...\n",
      "Policy Evaluation iteration 1, delta: 128.68143159150108\n",
      "Policy Evaluation iteration 2, delta: 88.9840515410105\n",
      "Policy Evaluation iteration 3, delta: 55.05565782565117\n",
      "Policy Evaluation iteration 4, delta: 30.814137257998027\n",
      "Policy Evaluation iteration 5, delta: 15.799621724498763\n",
      "Policy Evaluation iteration 6, delta: 7.536976059132769\n",
      "Policy Evaluation iteration 7, delta: 3.3714427480243785\n",
      "Policy Evaluation iteration 8, delta: 1.4376409283248108\n",
      "Policy Evaluation iteration 9, delta: 0.5861307513773113\n",
      "Policy Evaluation iteration 10, delta: 0.2313577715176791\n",
      "Policy Evaluation iteration 11, delta: 0.0894852826085355\n",
      "Policy Evaluation iteration 12, delta: 0.033899597249046565\n",
      "Policy Evaluation iteration 13, delta: 0.012649625481003568\n",
      "Policy Evaluation iteration 14, delta: 0.004668615256775865\n",
      "Policy Improvement...\n",
      "Number of policy changes: 390\n",
      "Iteration 2\n",
      "Policy Evaluation...\n",
      "Policy Evaluation iteration 1, delta: 256.1086717133408\n",
      "Policy Evaluation iteration 2, delta: 40.34439528767007\n",
      "Policy Evaluation iteration 3, delta: 20.073966717865858\n",
      "Policy Evaluation iteration 4, delta: 12.691321563104395\n",
      "Policy Evaluation iteration 5, delta: 7.806876585815019\n",
      "Policy Evaluation iteration 6, delta: 4.57560453916949\n",
      "Policy Evaluation iteration 7, delta: 2.605864485380721\n",
      "Policy Evaluation iteration 8, delta: 1.457638081011055\n",
      "Policy Evaluation iteration 9, delta: 0.8057076099483425\n",
      "Policy Evaluation iteration 10, delta: 0.4429859454485836\n",
      "Policy Evaluation iteration 11, delta: 0.24203387348711658\n",
      "Policy Evaluation iteration 12, delta: 0.131742839393155\n",
      "Policy Evaluation iteration 13, delta: 0.07143916061886557\n",
      "Policy Evaluation iteration 14, delta: 0.03862967740411705\n",
      "Policy Evaluation iteration 15, delta: 0.020844445015029578\n",
      "Policy Evaluation iteration 16, delta: 0.011229849101709988\n",
      "Policy Evaluation iteration 17, delta: 0.006042868603913121\n",
      "Policy Improvement...\n",
      "Number of policy changes: 211\n",
      "Iteration 3\n",
      "Policy Evaluation...\n",
      "Policy Evaluation iteration 1, delta: 21.70599657058466\n",
      "Policy Evaluation iteration 2, delta: 8.753957624203451\n",
      "Policy Evaluation iteration 3, delta: 4.904676011211336\n",
      "Policy Evaluation iteration 4, delta: 2.738952871823983\n",
      "Policy Evaluation iteration 5, delta: 1.5241214588114644\n",
      "Policy Evaluation iteration 6, delta: 0.8458803218912863\n",
      "Policy Evaluation iteration 7, delta: 0.46719920519342395\n",
      "Policy Evaluation iteration 8, delta: 0.25722303032540594\n",
      "Policy Evaluation iteration 9, delta: 0.1412897242935287\n",
      "Policy Evaluation iteration 10, delta: 0.07747079895347042\n",
      "Policy Evaluation iteration 11, delta: 0.04241956502727362\n",
      "Policy Evaluation iteration 12, delta: 0.02320226418476068\n",
      "Policy Evaluation iteration 13, delta: 0.012680493599589227\n",
      "Policy Evaluation iteration 14, delta: 0.006925734515618842\n",
      "Policy Improvement...\n",
      "Number of policy changes: 24\n",
      "Iteration 4\n",
      "Policy Evaluation...\n",
      "Policy Evaluation iteration 1, delta: 0.6356164062266316\n",
      "Policy Evaluation iteration 2, delta: 0.04697723010468735\n",
      "Policy Evaluation iteration 3, delta: 0.024954606850371874\n",
      "Policy Evaluation iteration 4, delta: 0.015039013411978885\n",
      "Policy Evaluation iteration 5, delta: 0.00837289073285774\n",
      "Policy Improvement...\n",
      "Number of policy changes: 0\n",
      "Policy is stable!\n"
     ]
    }
   ],
   "source": [
    "# V, policy = policy_iteration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize_value_policy(V, policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changes to Jack's Rental Car Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModifiedState(State):\n",
    "    def get_all_transitions(self, action: int) -> list[tuple[Self, float, int]]:\n",
    "        transitions = super().get_all_transitions(action)\n",
    "        \n",
    "        # Adjust transition rewards based on the exercise\n",
    "        modified_transitions = []\n",
    "        \n",
    "        for state, prob, reward in transitions:\n",
    "            # Jack's employee moves a car from loc1 to loc2 for free\n",
    "            if action > 0:\n",
    "                reward += 2\n",
    "            \n",
    "            # If there are >10 cars in either lot, then Jack pays $4 for a secondary lot for the location\n",
    "            if state.cars_loc1 > 10:\n",
    "                reward -= 4\n",
    "            if state.cars_loc2 > 10:\n",
    "                reward -= 4\n",
    "            modified_transitions.append((state, prob, reward))\n",
    "            \n",
    "        return modified_transitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallelizing Original Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze Poisson to reduce the space for rentals and returns\n",
    "def poisson_pmf(k, lambda_):\n",
    "    return (lambda_**k / math.factorial(k)) * np.exp(-lambda_)\n",
    "\n",
    "def analyze_poisson(lambda_, name):\n",
    "    probs = []\n",
    "    cumsum = 0\n",
    "    print(f\"\\nAnalysis for {name} (lambda={lambda_}):\")\n",
    "    print(\"k\\tProb\\tCumulative\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    for k in range(15):\n",
    "        prob = poisson_pmf(k, lambda_)\n",
    "        cumsum += prob\n",
    "        print(f\"{k}\\t{prob:.6f}\\t{cumsum:.6f}\")\n",
    "        if cumsum > 0.998:\n",
    "            print(f\"99.8% of probability mass covered by k≤{k}\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analysis for rental1/return1 (lambda=3):\n",
      "k\tProb\tCumulative\n",
      "------------------------------\n",
      "0\t0.049787\t0.049787\n",
      "1\t0.149361\t0.199148\n",
      "2\t0.224042\t0.423190\n",
      "3\t0.224042\t0.647232\n",
      "4\t0.168031\t0.815263\n",
      "5\t0.100819\t0.916082\n",
      "6\t0.050409\t0.966491\n",
      "7\t0.021604\t0.988095\n",
      "8\t0.008102\t0.996197\n",
      "9\t0.002701\t0.998898\n",
      "99.8% of probability mass covered by k≤9\n"
     ]
    }
   ],
   "source": [
    "# Analyze each Poisson distribution\n",
    "analyze_poisson(3, \"rental1/return1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analysis for rental2 (lambda=4):\n",
      "k\tProb\tCumulative\n",
      "------------------------------\n",
      "0\t0.018316\t0.018316\n",
      "1\t0.073263\t0.091578\n",
      "2\t0.146525\t0.238103\n",
      "3\t0.195367\t0.433470\n",
      "4\t0.195367\t0.628837\n",
      "5\t0.156293\t0.785130\n",
      "6\t0.104196\t0.889326\n",
      "7\t0.059540\t0.948866\n",
      "8\t0.029770\t0.978637\n",
      "9\t0.013231\t0.991868\n",
      "10\t0.005292\t0.997160\n",
      "11\t0.001925\t0.999085\n",
      "99.8% of probability mass covered by k≤11\n"
     ]
    }
   ],
   "source": [
    "analyze_poisson(4, \"rental2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analysis for return2 (lambda=2):\n",
      "k\tProb\tCumulative\n",
      "------------------------------\n",
      "0\t0.135335\t0.135335\n",
      "1\t0.270671\t0.406006\n",
      "2\t0.270671\t0.676676\n",
      "3\t0.180447\t0.857123\n",
      "4\t0.090224\t0.947347\n",
      "5\t0.036089\t0.983436\n",
      "6\t0.012030\t0.995466\n",
      "7\t0.003437\t0.998903\n",
      "99.8% of probability mass covered by k≤7\n"
     ]
    }
   ],
   "source": [
    "analyze_poisson(2, \"return2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building state class that uses tensors\n",
    "class TensorState(State):\n",
    "    # Poisson cutoffs for rentals and returns based on 99.9% of cumulative probability\n",
    "    RENTAL1_CUTOFF = 9  # lambda=3\n",
    "    RETURN1_CUTOFF = 9  # lambda=3\n",
    "    RENTAL2_CUTOFF = 11  # lambda=4\n",
    "    RETURN2_CUTOFF = 7   # lambda=2    \n",
    "    \n",
    "    def __init__(self):\n",
    "        # Initialize value function matrix. 0-20 cars at each location, so 21x21\n",
    "        self.V = np.zeros((21, 21), dtype=float)\n",
    "        \n",
    "        # Initialize policy as action for each state, so 21x21 again, with each value from [-5, 5]\n",
    "        self.policy = np.zeros((21, 21), dtype=int)\n",
    "        \n",
    "        # Initialize Q values as 21x21x11 (states x actions). 11 actions from -5 to 5\n",
    "        self.Q = np.zeros((21, 21, 11), dtype=float)\n",
    "        \n",
    "        # Compute Poisson probabilities for possible rental and return cutoffs\n",
    "        self.rental1_probs = poisson.pmf(k=np.arange(self.RENTAL1_CUTOFF + 1), mu=3)\n",
    "        self.return1_probs = poisson.pmf(k=np.arange(self.RETURN1_CUTOFF + 1), mu=3)\n",
    "        self.rental2_probs = poisson.pmf(k=np.arange(self.RENTAL2_CUTOFF + 1), mu=4)\n",
    "        self.return2_probs = poisson.pmf(k=np.arange(self.RETURN2_CUTOFF + 1), mu=2)\n",
    "        \n",
    "        # Action mask to mask out actions that cannot happen (21x21x11)\n",
    "        self.action_mask = self._initialize_action_mask()\n",
    "    \n",
    "    def _initialize_action_mask(self):\n",
    "        \"\"\"Initialize action mask based on valid car transfers\"\"\"\n",
    "        mask = np.zeros((21, 21, 11), dtype=bool)\n",
    "        \n",
    "        # Loop over possible cars at loc1\n",
    "        for i in range(21):\n",
    "            # Loop over possible cars at loc2\n",
    "            for j in range(21):\n",
    "                for a_idx, action in enumerate(range(-5, 6)):\n",
    "                    # Movement constraints\n",
    "                    valid = (action <= i) and (-action <= j)\n",
    "                    mask[i, j, a_idx] = valid\n",
    "\n",
    "        return mask\n",
    "    \n",
    "    def _action_idx_to_value(self, idx) -> int:\n",
    "        \"\"\"Converts action index to the action value\"\"\"\n",
    "        return idx - 5\n",
    "    \n",
    "    def get_post_action_states(self):\n",
    "        \"\"\"\n",
    "        Get states after making the action for all possible initial states and actions.\n",
    "        Returns:\n",
    "            post_states: (21, 21, 11, 2) tensor with last dim being [cars_loc1, cars_loc2]\n",
    "            move_rewards: (21, 21, 11) tensor of rewards for moving cars\n",
    "        \"\"\"\n",
    "        # Possible number of cars at a location\n",
    "        cars_at_loc = np.arange(21)\n",
    "        # Possible actions [-5, 5]\n",
    "        possible_actions = np.arange(-5, 6)\n",
    "        \n",
    "        # Meshgrid for states and actions\n",
    "        i, j, actions = np.meshgrid(cars_at_loc, cars_at_loc, possible_actions, indexing='ij')\n",
    "        \n",
    "        # New states after moving cars\n",
    "        post_loc1 = np.clip(i - actions, 0, 20)\n",
    "        post_loc2 = np.clip(j + actions, 0, 20)\n",
    "        \n",
    "        # Calculate rewards for movement\n",
    "        move_rewards = -2 * np.abs(actions)\n",
    "        \n",
    "        # Stack post_loc states into one array\n",
    "        post_states = np.stack([post_loc1, post_loc2], axis=-1)\n",
    "        \n",
    "        return post_states, move_rewards\n",
    "    \n",
    "    def get_rental_return_transitions(self, post_states):\n",
    "        \"\"\"\n",
    "        Compute transitions from rentals and returns for all states after car movements.\n",
    "        \n",
    "        Args:\n",
    "            post_states: (21, 21, 11, 2) tensor from get_post_action_states\n",
    "            \n",
    "        Returns:\n",
    "            - transition_probs: tensor containing probabilities for each combination\n",
    "            - rental_rewards: tensor containing rewards from rentals\n",
    "        \"\"\"\n",
    "        # Split post states into loc1 and loc 2\n",
    "        cars_loc1, cars_loc2 = post_states[..., 0], post_states[..., 1]\n",
    "        \n",
    "        # Possible returns and rentals at each location\n",
    "        possible_rentals1 = np.minimum(np.arange(self.RENTAL1_CUTOFF + 1)[:, None, None, None], cars_loc1)\n",
    "        possible_returns1 = np.arange(self.RETURN1_CUTOFF + 1)\n",
    "        possible_rentals2 = np.minimum(np.arange(self.RENTAL2_CUTOFF + 1)[:, None, None, None], cars_loc2)\n",
    "        possible_returns2 = np.arange(self.RETURN2_CUTOFF + 1)\n",
    "        \n",
    "        # Calculate probabilities for each combination with einsum\n",
    "        probs = np.einsum('i,j,k,l->ijkl',\n",
    "                          self.rental1_probs,\n",
    "                          self.return1_probs,\n",
    "                          self.rental2_probs,\n",
    "                          self.return2_probs,\n",
    "                          )\n",
    "        \n",
    "        return probs\n",
    "    \n",
    "    def create_transition_mask(self, post_states, location):\n",
    "        match location:\n",
    "            case 1:\n",
    "                loc = 0\n",
    "                rental_cutoff = self.RENTAL1_CUTOFF\n",
    "                return_cutoff = self.RETURN1_CUTOFF\n",
    "            case 2:\n",
    "                loc = 1\n",
    "                rental_cutoff = self.RENTAL2_CUTOFF\n",
    "                return_cutoff = self.RETURN2_CUTOFF\n",
    "        \n",
    "        # Split post states into loc1 and loc 2\n",
    "        cars = post_states[..., loc] # Shape: (21, 21, 11)\n",
    "        \n",
    "        # Reshape cars for broadcasting:\n",
    "        cars = cars.reshape(1, 1, 21, 21, 11)\n",
    "        \n",
    "        # Broadcast for loc1\n",
    "        rentals = np.arange(rental_cutoff + 1).reshape(-1, 1, 1, 1, 1)\n",
    "        returns = np.arange(return_cutoff + 1).reshape(1, -1, 1, 1, 1)\n",
    "        \n",
    "        mask = ((0 <= cars - rentals + returns) & (cars - rentals + returns <= 20))\n",
    "        \n",
    "        return mask\n",
    "    \n",
    "    def get_valid_transitions(self, post_states):\n",
    "        \"\"\"\n",
    "        Get valid transitions using a mask and their probabilities\n",
    "\n",
    "        Args:\n",
    "            post_states: (21, 21, 11, 2) tensor from get_post_action_states\n",
    "        \n",
    "        Returns:\n",
    "            valid_indices: indicies in the transitions matrix that are valid\n",
    "            probs: probabilities of the transitions matrix\n",
    "        \"\"\"\n",
    "        # Get basic action mask and reshape to match final dimensions\n",
    "        valid_mask = self.action_mask.reshape(1, 1, 1, 1, 21, 21, 11).copy()\n",
    "        # Expand dimensions to match mask1's shape\n",
    "        valid_mask = np.broadcast_to(valid_mask, \n",
    "                                     (self.RENTAL1_CUTOFF + 1, \n",
    "                                      self.RETURN1_CUTOFF + 1, \n",
    "                                      1, 1, 21, 21, 11),\n",
    "                                     )\n",
    "        \n",
    "        # Apply location 1 constraints\n",
    "        mask1 = self.create_transition_mask(post_states, location=1)\n",
    "        valid_mask = mask1.reshape(self.RENTAL1_CUTOFF + 1, \n",
    "                                    self.RETURN1_CUTOFF + 1, \n",
    "                                    1, 1, 21, 21, 11)\n",
    "        \n",
    "        # Apply location 2 constraints\n",
    "        mask2 = self.create_transition_mask(post_states, location=2)\n",
    "        valid_mask = mask2.reshape(1, 1, \n",
    "                                    self.RENTAL2_CUTOFF + 1, \n",
    "                                    self.RETURN2_CUTOFF + 1, \n",
    "                                    21, 21, 11)\n",
    "        \n",
    "        # Get indices where valid\n",
    "        valid_indices = np.where(valid_mask)\n",
    "        \n",
    "        # Calculate probabilities for valid transitions\n",
    "        rentals1, returns1, rentals2, returns2, i, j, a = valid_indices\n",
    "        \n",
    "        probs = (self.rental1_probs[rentals1] * \n",
    "                self.return1_probs[returns1] * \n",
    "                self.rental2_probs[rentals2] * \n",
    "                self.return2_probs[returns2])\n",
    "        \n",
    "        # Flatten state-action indices for grouping\n",
    "        state_action_indices = (i * 21 * 11) + (j * 11) + a\n",
    "        \n",
    "        # Sum probabilities for each state-action pair\n",
    "        prob_sums = np.bincount(state_action_indices, weights=probs, minlength=21*21*11)\n",
    "        \n",
    "        # normalize probabilities for each state-action pair\n",
    "        normalized_probs = probs / prob_sums[state_action_indices]\n",
    "        \n",
    "        return valid_indices, normalized_probs\n",
    "    \n",
    "    def calculate_rewards(self, valid_indices, move_rewards):\n",
    "        \"\"\"\n",
    "        Calculate rewards for valid transitions\n",
    "\n",
    "        Args:\n",
    "            valid_indices: tuple of (rentals1, returns1, rentals2, returns2, i, j, a) indices\n",
    "            move_rewards: (21, 21, 11) tensor of movement rewards from get_post_action_states\n",
    "\n",
    "        Returns:\n",
    "            total_reward: array of (rentals1, returns1, rentals2, returns2, i, j, a) rewards from valid transitions\n",
    "        \"\"\"\n",
    "        rentals1, returns1, rentals2, returns2, i, j, a = valid_indices\n",
    "        \n",
    "        # Movement rewards for valid transitions\n",
    "        movement_reward = move_rewards[i, j, a]\n",
    "        \n",
    "        # Rental rewards ($10 for each rental)\n",
    "        rental_reward = 10 * (rentals1 + rentals2)\n",
    "        \n",
    "        # Total reward\n",
    "        total_reward = movement_reward + rental_reward\n",
    "        \n",
    "        return total_reward\n",
    "    \n",
    "    def calculate_next_states(self, valid_indices, post_states):\n",
    "        \"\"\"\n",
    "        Calculate next states for valid transitions\n",
    "        \n",
    "        Args:\n",
    "            valid_indices: tuple of (rentals1, returns1, rentals2, returns2, i, j, a)\n",
    "            post_states: (21, 21, 11, 2) tensor from get_post_action_states\n",
    "            \n",
    "        Returns:\n",
    "            next_states: Array of shape (num_valid_transitions, 2) containing [next_cars1, next_cars2] for each valid transition\n",
    "        \"\"\"\n",
    "        rentals1, returns1, rentals2, returns2, i, j, a = valid_indices\n",
    "        \n",
    "        # Get post-action states for these indices\n",
    "        post_cars1 = post_states[i, j, a, 0]  # Cars at loc1 after moving\n",
    "        post_cars2 = post_states[i, j, a, 1]  # Cars at loc2 after moving\n",
    "        \n",
    "        # Calculate next states after rentals and returns\n",
    "        next_cars1 = post_cars1 - rentals1 + returns1\n",
    "        next_cars2 = post_cars2 - rentals2 + returns2\n",
    "        \n",
    "        # Stack into single array\n",
    "        next_states = np.stack([next_cars1, next_cars2], axis=1)\n",
    "        \n",
    "        return next_states\n",
    "    \n",
    "    def policy_evaluation(self, theta: float=0.01, gamma: float=0.9) -> None:\n",
    "        \"\"\"Policy Evaluation using vectorized operations\"\"\"\n",
    "        eval_iteration = 0\n",
    "        \n",
    "        while True:\n",
    "            delta = 0\n",
    "            old_V = self.V.copy()\n",
    "            \n",
    "            # Get states and rewards after we take our action\n",
    "            post_states, move_rewards = self.get_post_action_states()\n",
    "            \n",
    "            # Debug: Check move_rewards\n",
    "            print(\"Move rewards range:\", np.min(move_rewards), np.max(move_rewards))\n",
    "            \n",
    "            # Get valid transitions and probabilities\n",
    "            valid_indices, probs = self.get_valid_transitions(post_states)\n",
    "            \n",
    "            # Debug: Check probabilities\n",
    "            print(\"Probability sum:\", np.sum(probs))\n",
    "            print(\"Probability range:\", np.min(probs), np.max(probs))\n",
    "            \n",
    "            # Get rewards\n",
    "            total_rewards = self.calculate_rewards(valid_indices, move_rewards)\n",
    "            \n",
    "            # Debug: Check total rewards\n",
    "            print(\"Total rewards range:\", np.min(total_rewards), np.max(total_rewards))\n",
    "            \n",
    "            # Get next states\n",
    "            next_states = self.calculate_next_states(valid_indices, post_states)\n",
    "            \n",
    "            # Calculate next state values\n",
    "            next_state_values = self.V[next_states[:, 0], next_states[:, 1]]\n",
    "            \n",
    "            # Expected values for each transition\n",
    "            expected_values = probs * (total_rewards + gamma * next_state_values)\n",
    "            \n",
    "            # Debug: Check expected values\n",
    "            print(\"Expected values range:\", np.min(expected_values), np.max(expected_values))\n",
    "            \n",
    "            # Need to sum up values for each starting state (i, j)\n",
    "            i, j = valid_indices[4], valid_indices[5] # Starting indices\n",
    "            state_indices = i * 21 + j # Flatten indices\n",
    "            \n",
    "            # Sum values over each state and set back to V matrix\n",
    "            self.V = np.bincount(state_indices, \n",
    "                                 weights=expected_values, \n",
    "                                 minlength=21*21,\n",
    "                                 ).reshape(21, 21)\n",
    "            \n",
    "            # Calculate delta\n",
    "            delta = np.max(np.abs(old_V - self.V))\n",
    "            \n",
    "            eval_iteration += 1\n",
    "            print(f\"Policy Evaluation iteration {eval_iteration}, delta: {delta}\")\n",
    "            \n",
    "            if delta < theta:\n",
    "                break\n",
    "    \n",
    "    def policy_improvement(self, gamma: float=0.9):\n",
    "        \"\"\"Policy Improvement using vectorized operations\"\"\"\n",
    "        policy_stable = True\n",
    "        \n",
    "        # Set old actions\n",
    "        old_policy = self.policy.copy()\n",
    "        \n",
    "        # Get states and rewards after action is made\n",
    "        post_states, move_rewards = self.get_post_action_states()\n",
    "        \n",
    "        # Get valid transitions and probabilities\n",
    "        valid_indices, probs = self.get_valid_transitions(post_states)\n",
    "        \n",
    "        # Get rewards\n",
    "        total_rewards = self.calculate_rewards(valid_indices, move_rewards)\n",
    "        \n",
    "        # Get next states\n",
    "        next_states = self.calculate_next_states(valid_indices, post_states)\n",
    "        \n",
    "        # Calculate next state values\n",
    "        next_state_values = self.V[next_states[:, 0], next_states[:, 1]]\n",
    "        \n",
    "        # Action values for each transition\n",
    "        action_values = probs * (total_rewards + gamma * next_state_values)\n",
    "        \n",
    "        # Sum values for state-action pairs\n",
    "        i, j, a = valid_indices[4], valid_indices[5], valid_indices[6] # (s=(s1, s2), a)\n",
    "        state_action_indices = (i * 21 * 11) + (j * 11) + a # Flatten indices\n",
    "        Q = np.bincount(state_action_indices, \n",
    "                        weights=action_values, \n",
    "                        minlength=21*21*11,\n",
    "                        ).reshape(21, 21, 11)\n",
    "        \n",
    "        # Find best action for each states\n",
    "        self.policy = self._action_idx_to_value(np.argmax(Q, axis=2)) # Convert action index to action value\n",
    "        \n",
    "        # Check if policy-stable\n",
    "        policy_changes = np.sum(old_policy != self.policy)\n",
    "        policy_stable = (policy_changes == 0)\n",
    "        \n",
    "        print(f\"Number of policy changes: {policy_changes}\")\n",
    "\n",
    "        return policy_stable\n",
    "    \n",
    "    def visualize_iteration(self, iteration: int, save_figs: bool = True):\n",
    "        \"\"\"Visualize current value function and policy\"\"\"\n",
    "        plt.figure(figsize=(12, 5))\n",
    "        \n",
    "        # Plot values\n",
    "        plt.subplot(121)\n",
    "        plt.imshow(self.V, origin='lower')\n",
    "        plt.colorbar(label='Value')\n",
    "        plt.title(f'State Values (Iteration {iteration})')\n",
    "        plt.xlabel('Cars at Location 2')\n",
    "        plt.ylabel('Cars at Location 1')\n",
    "        plt.xticks(range(0, 21, 5))\n",
    "        plt.yticks(range(0, 21, 5))\n",
    "        \n",
    "        # Plot policy\n",
    "        plt.subplot(122)\n",
    "        plt.imshow(self.policy, origin='lower')\n",
    "        plt.colorbar(label='Action')\n",
    "        plt.title(f'Policy (Iteration {iteration})')\n",
    "        plt.xlabel('Cars at Location 2')\n",
    "        plt.ylabel('Cars at Location 1')\n",
    "        plt.xticks(range(0, 21, 5))\n",
    "        plt.yticks(range(0, 21, 5))\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        if save_figs:\n",
    "            plt.savefig(f'iteration_{iteration}.png')\n",
    "        plt.close()\n",
    "    \n",
    "    def display_all_iterations(self, num_iterations):\n",
    "        \"\"\"Display all saved iterations in a grid\"\"\"\n",
    "        # Calculate grid dimensions\n",
    "        grid_size = int(np.ceil(np.sqrt(num_iterations)))\n",
    "        \n",
    "        plt.figure(figsize=(4*grid_size, 4*grid_size))\n",
    "        for i in range(num_iterations):\n",
    "            plt.subplot(grid_size, grid_size, i+1)\n",
    "            img = plt.imread(f'iteration_{i+1}.png')\n",
    "            plt.imshow(img)\n",
    "            plt.axis('off')\n",
    "            plt.title(f'Iteration {i+1}')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def policy_iteration(self, theta: float=0.01, gamma: float=0.9):\n",
    "        \"\"\"Policy Iteration Algorithm using vectorized operations\"\"\"\n",
    "        iteration = 0\n",
    "        \n",
    "        while True:\n",
    "            iteration += 1\n",
    "            print(f\"\\nIteration {iteration}\")\n",
    "            \n",
    "            # Policy Evaluation\n",
    "            print(\"Policy Evaluation...\")\n",
    "            self.policy_evaluation(theta, gamma)\n",
    "            \n",
    "            # Policy Improvement\n",
    "            print(\"Policy Improvement...\")\n",
    "            policy_stable = self.policy_improvement(gamma)\n",
    "            \n",
    "            # Visualize and save current state\n",
    "            self.visualize_iteration(iteration)\n",
    "            \n",
    "            if policy_stable:\n",
    "                print(\"Policy stable!\")\n",
    "                break\n",
    "        \n",
    "        # Display all iterations at the end\n",
    "        self.display_all_iterations(iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 1\n",
      "Policy Evaluation...\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: -0.18431935908689795 3.9321463271871537\n",
      "Policy Evaluation iteration 1, delta: 404.0066203421486\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 0.002303363701693048 33.33038409298156\n",
      "Policy Evaluation iteration 2, delta: 3867.7282306952275\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 0.018616091699713275 368.1217606266299\n",
      "Policy Evaluation iteration 3, delta: 37216.44408677007\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 0.18144601373255653 3810.3470059477518\n",
      "Policy Evaluation iteration 4, delta: 353339.36643358064\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1.7977926749022952 38533.14361384819\n",
      "Policy Evaluation iteration 5, delta: 3337810.5925807934\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 17.81869686353431 386052.416004292\n",
      "Policy Evaluation iteration 6, delta: 31611295.152248483\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 176.46713618542157 3850412.8118630857\n",
      "Policy Evaluation iteration 7, delta: 301193902.52038443\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1748.1086684453076 38307929.896933354\n",
      "Policy Evaluation iteration 8, delta: 2889631297.260708\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 17308.202151008787 380550283.74816275\n",
      "Policy Evaluation iteration 9, delta: 27902478146.75804\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 171288.76982027447 3776651390.248615\n",
      "Policy Evaluation iteration 10, delta: 270921952332.1811\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1695388.1719207065 37454980348.334625\n",
      "Policy Evaluation iteration 11, delta: 2642421495545.6914\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 16782009.540370405 371284381106.7678\n",
      "Policy Evaluation iteration 12, delta: 25864688442326.324\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 166122190.35318235 3679222817719.428\n",
      "Policy Evaluation iteration 13, delta: 253870978717939.03\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1643992709.344714 36450033133473.414\n",
      "Policy Evaluation iteration 14, delta: 2497117822209110.0\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 16271027584.0289 361044498683130.5\n",
      "Policy Evaluation iteration 15, delta: 2.4601657828965784e+16\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 161050197275.5942 3575733572497129.5\n",
      "Policy Evaluation iteration 16, delta: 2.4267120358676912e+17\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1594154635963.424 3.541002989782173e+16\n",
      "Policy Evaluation iteration 17, delta: 2.39590712670695e+18\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 15780347178958.305 3.506350159968635e+17\n",
      "Policy Evaluation iteration 18, delta: 2.367120678018776e+19\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 156211030063779.5 3.471845259626275e+18\n",
      "Policy Evaluation iteration 19, delta: 2.339885550396795e+20\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1546292767398910.2 3.437538982656479e+19\n",
      "Policy Evaluation iteration 20, delta: 2.3138557833612938e+21\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1.5306849097502586e+16 3.403467763189296e+20\n",
      "Policy Evaluation iteration 21, delta: 2.288775172880327e+22\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1.515271112261774e+17 3.3696575690467563e+21\n",
      "Policy Evaluation iteration 22, delta: 2.2644539085433163e+23\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1.5000394732480156e+18 3.336126674058234e+22\n",
      "Policy Evaluation iteration 23, delta: 2.2407512531986347e+24\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1.4849808264709124e+19 3.302887691871442e+23\n",
      "Policy Evaluation iteration 24, delta: 2.217562724531172e+25\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1.4700880243211487e+20 3.2699490714895193e+24\n",
      "Policy Evaluation iteration 25, delta: 2.1948106183617234e+26\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1.45535541107105e+21 3.2373161985634595e+25\n",
      "Policy Evaluation iteration 26, delta: 2.1724370069268533e+27\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1.4407784351079772e+22 3.204992207062269e+26\n",
      "Policy Evaluation iteration 27, delta: 2.150398567738149e+28\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1.4263533631618799e+23 3.172978577786687e+27\n",
      "Policy Evaluation iteration 28, delta: 2.1286627652992656e+29\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1.412077069551762e+24 3.1412755798275045e+28\n",
      "Policy Evaluation iteration 29, delta: 2.1072050321352937e+30\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1.3979468806860734e+25 3.1098825962247516e+29\n",
      "Policy Evaluation iteration 30, delta: 2.0860066877620778e+31\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1.3839604602936957e+26 3.0787983642111316e+30\n",
      "Policy Evaluation iteration 31, delta: 2.0650534024862957e+32\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1.370115724694957e+27 3.048021152435337e+31\n",
      "Policy Evaluation iteration 32, delta: 2.0443340634173475e+33\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1.3564107802350684e+28 3.0175488916817855e+32\n",
      "Policy Evaluation iteration 33, delta: 2.023839937385224e+34\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1.3428438770713645e+29 2.9873792712715626e+33\n",
      "Policy Evaluation iteration 34, delta: 2.0035640530207637e+35\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1.329413375029574e+30 2.9575098101355444e+34\n",
      "Policy Evaluation iteration 35, delta: 1.983500744607515e+36\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1.3161177183677087e+31 2.927937909194792e+35\n",
      "Policy Evaluation iteration 36, delta: 1.9636453153414982e+37\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1.3029554171146484e+32 2.898660889944775e+36\n",
      "Policy Evaluation iteration 37, delta: 1.943993788728312e+38\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1.2899250332616814e+33 2.869676022857767e+37\n",
      "Policy Evaluation iteration 38, delta: 1.9245427250360207e+39\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1.277025170536309e+34 2.8409805482706453e+38\n",
      "Policy Evaluation iteration 39, delta: 1.9052890857667585e+40\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1.2642544668204447e+35 2.812571691727061e+39\n",
      "Policy Evaluation iteration 40, delta: 1.8862301335720473e+41\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1.2516115885207739e+36 2.784446675227054e+40\n",
      "Policy Evaluation iteration 41, delta: 1.8673633583295893e+42\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1.2390952263803206e+37 2.756602725456675e+41\n",
      "Policy Evaluation iteration 42, delta: 1.8486864225307322e+43\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1.226704092354147e+38 2.7290370797893255e+42\n",
      "Policy Evaluation iteration 43, delta: 1.8301971209216897e+44\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1.2144369172707838e+39 2.7017469906430913e+43\n",
      "Policy Evaluation iteration 44, delta: 1.811893350665926e+45\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1.2022924490739652e+40 2.674729728625313e+44\n",
      "Policy Evaluation iteration 45, delta: 1.7937730892729518e+46\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1.1902694514929752e+41 2.6479825847828368e+45\n",
      "Policy Evaluation iteration 46, delta: 1.7758343782599347e+47\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1.1783667030297276e+42 2.621502872192721e+46\n",
      "Policy Evaluation iteration 47, delta: 1.7580753110450754e+48\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1.1665829961798707e+43 2.5952879270669443e+47\n",
      "Policy Evaluation iteration 48, delta: 1.7404940239652304e+49\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1.1549171368270345e+44 2.569335109499057e+48\n",
      "Policy Evaluation iteration 49, delta: 1.723088689599786e+50\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1.143367943765076e+45 2.543641803947235e+49\n",
      "Policy Evaluation iteration 50, delta: 1.7058575117973462e+51\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1.1319342483151896e+46 2.5182054195234324e+50\n",
      "Policy Evaluation iteration 51, delta: 1.6887987219596893e+52\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1.1206148940133188e+47 2.493023390140099e+51\n",
      "Policy Evaluation iteration 52, delta: 1.671910576254299e+53\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1.1094087363497217e+48 2.468093174552509e+52\n",
      "Policy Evaluation iteration 53, delta: 1.655191353512508e+54\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1.0983146425473886e+49 2.443412256324507e+53\n",
      "Policy Evaluation iteration 54, delta: 1.6386393536343448e+55\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1.0873314913693722e+50 2.4189781437386227e+54\n",
      "Policy Evaluation iteration 55, delta: 1.6222528963677145e+56\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1.0764581729478012e+51 2.394788369665588e+55\n",
      "Policy Evaluation iteration 56, delta: 1.6060303203643657e+57\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1.0656935886291395e+52 2.3708404914045954e+56\n",
      "Policy Evaluation iteration 57, delta: 1.5899699824404785e+58\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1.055036650831757e+53 2.347132090502642e+57\n",
      "Policy Evaluation iteration 58, delta: 1.5740702569888738e+59\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1.044486282912852e+54 2.323660772558962e+58\n",
      "Policy Evaluation iteration 59, delta: 1.5583295355034067e+60\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1.0340414190425592e+55 2.300424167019164e+59\n",
      "Policy Evaluation iteration 60, delta: 1.5427462261866703e+61\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1.0237010040836471e+56 2.2774199269623135e+60\n",
      "Policy Evaluation iteration 61, delta: 1.527318753619593e+62\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1.0134639934755852e+57 2.2546457288835066e+61\n",
      "Policy Evaluation iteration 62, delta: 1.5120455584770615e+63\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1.0033293531221583e+58 2.232099272473617e+62\n",
      "Policy Evaluation iteration 63, delta: 1.4969250972780153e+64\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 9.932960592819112e+58 2.209778280397638e+63\n",
      "Policy Evaluation iteration 64, delta: 1.4819558421612971e+65\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 9.833630984609988e+59 2.1876804980725124e+64\n",
      "Policy Evaluation iteration 65, delta: 1.4671362806810306e+66\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 9.73529467308032e+60 2.1658036934452303e+65\n",
      "Policy Evaluation iteration 66, delta: 1.452464915616609e+67\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 9.637941725106884e+61 2.1441456567716528e+66\n",
      "Policy Evaluation iteration 67, delta: 1.4379402647940868e+68\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 9.541562306938585e+62 2.122704200396492e+67\n",
      "Policy Evaluation iteration 68, delta: 1.4235608609162002e+69\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 9.446146683192194e+63 2.1014771585346529e+68\n",
      "Policy Evaluation iteration 69, delta: 1.4093252513992117e+70\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 9.351685215860559e+64 2.0804623870542062e+69\n",
      "Policy Evaluation iteration 70, delta: 1.3952319982151475e+71\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 9.258168363333117e+65 2.0596577632610955e+70\n",
      "Policy Evaluation iteration 71, delta: 1.38127967773841e+72\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 9.165586679427551e+66 2.0390611856856372e+71\n",
      "Policy Evaluation iteration 72, delta: 1.367466880595967e+73\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 9.073930812432355e+67 2.018670573870958e+72\n",
      "Policy Evaluation iteration 73, delta: 1.3537922115205487e+74\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 8.983191504159707e+68 1.9984838681633876e+73\n",
      "Policy Evaluation iteration 74, delta: 1.3402542892064593e+75\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 8.89335958900864e+69 1.978499029504735e+74\n",
      "Policy Evaluation iteration 75, delta: 1.3268517461676e+76\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 8.804425993037741e+70 1.958714039226649e+75\n",
      "Policy Evaluation iteration 76, delta: 1.3135832285975688e+77\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 8.716381733047746e+71 1.939126898846904e+76\n",
      "Policy Evaluation iteration 77, delta: 1.3004473962316202e+78\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 8.629217915673252e+72 1.919735629867676e+77\n",
      "Policy Evaluation iteration 78, delta: 1.2874429222102708e+79\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 8.542925736484019e+73 1.9005382735758193e+78\n",
      "Policy Evaluation iteration 79, delta: 1.2745684929445948e+80\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 8.457496479095184e+74 1.881532890845098e+79\n",
      "Policy Evaluation iteration 80, delta: 1.261822807982997e+81\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 8.372921514286522e+75 1.8627175619403663e+80\n",
      "Policy Evaluation iteration 81, delta: 1.2492045798794297e+82\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 8.289192299130607e+76 1.8440903863237035e+81\n",
      "Policy Evaluation iteration 82, delta: 1.2367125340631155e+83\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 8.206300376129663e+77 1.825649482462491e+82\n",
      "Policy Evaluation iteration 83, delta: 1.2243454087095598e+84\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 8.124237372361234e+78 1.8073929876393614e+83\n",
      "Policy Evaluation iteration 84, delta: 1.2121019546129111e+85\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 8.042994998632381e+79 1.7893190577640693e+84\n",
      "Policy Evaluation iteration 85, delta: 1.1999809350597418e+86\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 7.96256504864218e+80 1.7714258671872414e+85\n",
      "Policy Evaluation iteration 86, delta: 1.1879811257039409e+87\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 7.882939398152882e+81 1.7537116085159682e+86\n",
      "Policy Evaluation iteration 87, delta: 1.1761013144430612e+88\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 7.804110004169237e+82 1.7361744924312514e+87\n",
      "Policy Evaluation iteration 88, delta: 1.1643403012957989e+89\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 7.726068904125987e+83 1.7188127475072634e+88\n",
      "Policy Evaluation iteration 89, delta: 1.1526968982807503e+90\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 7.648808215083576e+84 1.701624620032435e+89\n",
      "Policy Evaluation iteration 90, delta: 1.1411699292963958e+91\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 7.57232013293189e+85 1.6846083738322874e+90\n",
      "Policy Evaluation iteration 91, delta: 1.129758230002291e+92\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 7.496596931601953e+86 1.6677622900940964e+91\n",
      "Policy Evaluation iteration 92, delta: 1.1184606477014261e+93\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 7.421630962285461e+87 1.651084667193252e+92\n",
      "Policy Evaluation iteration 93, delta: 1.1072760412237943e+94\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 7.347414652662272e+88 1.634573820521389e+93\n",
      "Policy Evaluation iteration 94, delta: 1.0962032808111006e+95\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 7.273940506135397e+89 1.6182280823162303e+94\n",
      "Policy Evaluation iteration 95, delta: 1.0852412480026466e+96\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 7.201201101073854e+90 1.6020458014931053e+95\n",
      "Policy Evaluation iteration 96, delta: 1.0743888355223766e+97\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 7.129189090062975e+91 1.5860253434782008e+96\n",
      "Policy Evaluation iteration 97, delta: 1.0636449471669656e+98\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 7.057897199162227e+92 1.5701650900434384e+97\n",
      "Policy Evaluation iteration 98, delta: 1.0530084976951572e+99\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 6.987318227170528e+93 1.554463439143019e+98\n",
      "Policy Evaluation iteration 99, delta: 1.0424784127181031e+100\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 6.91744504489877e+94 1.5389188047516039e+99\n",
      "Policy Evaluation iteration 100, delta: 1.032053628590854e+101\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 6.848270594449738e+95 1.5235296167040975e+100\n",
      "Policy Evaluation iteration 101, delta: 1.0217330923048886e+102\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 6.779787888505211e+96 1.5082943205370585e+101\n",
      "Policy Evaluation iteration 102, delta: 1.0115157613817958e+103\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 6.7119900096201366e+97 1.4932113773316936e+102\n",
      "Policy Evaluation iteration 103, delta: 1.0014006037679492e+104\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 6.644870109523916e+98 1.4782792635583796e+103\n",
      "Policy Evaluation iteration 104, delta: 9.913865977302475e+104\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 6.578421408428661e+99 1.463496470922796e+104\n",
      "Policy Evaluation iteration 105, delta: 9.814727317529292e+105\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 6.5126371943443544e+100 1.4488615062135681e+105\n",
      "Policy Evaluation iteration 106, delta: 9.716580044353858e+106\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 6.447510822400917e+101 1.434372891151435e+106\n",
      "Policy Evaluation iteration 107, delta: 9.61941424391024e+107\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 6.383035714176889e+102 1.4200291622399207e+107\n",
      "Policy Evaluation iteration 108, delta: 9.52322010147111e+108\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 6.3192053570351155e+103 1.4058288706175222e+108\n",
      "Policy Evaluation iteration 109, delta: 9.427987900456346e+109\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 6.256013303464752e+104 1.3917705819113464e+109\n",
      "Policy Evaluation iteration 110, delta: 9.333708021451689e+110\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 6.193453170430102e+105 1.3778528760922314e+110\n",
      "Policy Evaluation iteration 111, delta: 9.240370941237165e+111\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 6.1315186387258e+106 1.3640743473313093e+111\n",
      "Policy Evaluation iteration 112, delta: 9.147967231824786e+112\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 6.070203452338537e+107 1.350433603857994e+112\n",
      "Policy Evaluation iteration 113, delta: 9.056487559506489e+113\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 6.009501417815141e+108 1.3369292678194157e+113\n",
      "Policy Evaluation iteration 114, delta: 8.965922683911419e+114\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 5.9494064036369874e+109 1.3235599751412223e+114\n",
      "Policy Evaluation iteration 115, delta: 8.876263457072307e+115\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 5.8899123396006234e+110 1.310324375389813e+115\n",
      "Policy Evaluation iteration 116, delta: 8.78750082250158e+116\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 5.83101321620462e+111 1.2972211316359128e+116\n",
      "Policy Evaluation iteration 117, delta: 8.699625814276544e+117\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 5.7727030840425695e+112 1.284248920319553e+117\n",
      "Policy Evaluation iteration 118, delta: 8.612629556133776e+118\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 5.714976053202153e+113 1.2714064311163584e+118\n",
      "Policy Evaluation iteration 119, delta: 8.526503260572437e+119\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 5.657826292670124e+114 1.2586923668051971e+119\n",
      "Policy Evaluation iteration 120, delta: 8.441238227966722e+120\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 5.601248029743403e+115 1.2461054431371447e+120\n",
      "Policy Evaluation iteration 121, delta: 8.356825845687063e+121\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 5.545235549445976e+116 1.2336443887057739e+121\n",
      "Policy Evaluation iteration 122, delta: 8.273257587230198e+122\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 5.489783193951527e+117 1.221307944818719e+122\n",
      "Policy Evaluation iteration 123, delta: 8.190525011357892e+123\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 5.43488536201201e+118 1.2090948653705315e+123\n",
      "Policy Evaluation iteration 124, delta: 8.108619761244304e+124\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 5.380536508391893e+119 1.1970039167168231e+124\n",
      "Policy Evaluation iteration 125, delta: 8.02753356363186e+125\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 5.326731143307973e+120 1.185033877549656e+125\n",
      "Policy Evaluation iteration 126, delta: 7.947258227995529e+126\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 5.2734638318748885e+121 1.1731835387741579e+126\n",
      "Policy Evaluation iteration 127, delta: 7.867785645715573e+127\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 5.220729193556145e+122 1.1614517033864134e+127\n",
      "Policy Evaluation iteration 128, delta: 7.789107789258414e+128\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 5.168521901620586e+123 1.1498371863525504e+128\n",
      "Policy Evaluation iteration 129, delta: 7.711216711365842e+129\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 5.116836682604371e+124 1.1383388144890258e+129\n",
      "Policy Evaluation iteration 130, delta: 7.63410454425219e+130\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 5.0656683157783284e+125 1.1269554263441373e+130\n",
      "Policy Evaluation iteration 131, delta: 7.557763498809662e+131\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 5.01501163262055e+126 1.1156858720806964e+131\n",
      "Policy Evaluation iteration 132, delta: 7.482185863821565e+132\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 4.964861516294331e+127 1.1045290133598893e+132\n",
      "Policy Evaluation iteration 133, delta: 7.407364005183338e+133\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 4.915212901131395e+128 1.0934837232262888e+133\n",
      "Policy Evaluation iteration 134, delta: 7.333290365131516e+134\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 4.866060772120093e+129 1.0825488859940268e+134\n",
      "Policy Evaluation iteration 135, delta: 7.259957461480204e+135\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 4.817400164398878e+130 1.0717233971340879e+135\n",
      "Policy Evaluation iteration 136, delta: 7.187357886865392e+136\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 4.769226162754898e+131 1.0610061631627458e+136\n",
      "Policy Evaluation iteration 137, delta: 7.115484307996733e+137\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 4.7215339011273464e+132 1.0503961015311164e+137\n",
      "Policy Evaluation iteration 138, delta: 7.044329464916761e+138\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 4.674318562116073e+133 1.039892140515805e+138\n",
      "Policy Evaluation iteration 139, delta: 6.973886170267593e+139\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 4.62757537649491e+134 1.0294932191106462e+139\n",
      "Policy Evaluation iteration 140, delta: 6.904147308564926e+140\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 4.5812996227299516e+135 1.0191982869195371e+140\n",
      "Policy Evaluation iteration 141, delta: 6.835105835479275e+141\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 4.535486626502662e+136 1.009006304050341e+141\n",
      "Policy Evaluation iteration 142, delta: 6.766754777124504e+142\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 4.4901317602376284e+137 9.989162410098383e+141\n",
      "Policy Evaluation iteration 143, delta: 6.6990872293532434e+143\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 4.445230442635257e+138 9.889270785997405e+142\n",
      "Policy Evaluation iteration 144, delta: 6.632096357059704e+144\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 4.400778138208906e+139 9.790378078137448e+143\n",
      "Policy Evaluation iteration 145, delta: 6.565775393489101e+145\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 4.356770356826814e+140 9.692474297356065e+144\n",
      "Policy Evaluation iteration 146, delta: 6.500117639554214e+146\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 4.313202653258541e+141 9.59554955438253e+145\n",
      "Policy Evaluation iteration 147, delta: 6.435116463158668e+147\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 4.270070626725962e+142 9.499594058838688e+146\n",
      "Policy Evaluation iteration 148, delta: 6.370765298527077e+148\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 4.227369920458702e+143 9.404598118250301e+147\n",
      "Policy Evaluation iteration 149, delta: 6.3070576455418135e+149\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 4.185096221254118e+144 9.31055213706781e+148\n",
      "Policy Evaluation iteration 150, delta: 6.243987069086392e+150\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 4.143245259041568e+145 9.217446615697124e+149\n",
      "Policy Evaluation iteration 151, delta: 6.181547198395536e+151\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 4.101812806451147e+146 9.125272149540172e+150\n",
      "Policy Evaluation iteration 152, delta: 6.119731726411579e+152\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 4.060794678386636e+147 9.034019428044768e+151\n",
      "Policy Evaluation iteration 153, delta: 6.058534409147457e+153\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 4.0201867316027815e+148 8.943679233764312e+152\n",
      "Policy Evaluation iteration 154, delta: 5.997949065055981e+154\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 3.979984864286745e+149 8.85424244142665e+153\n",
      "Policy Evaluation iteration 155, delta: 5.937969574405421e+155\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 3.9401850156438776e+150 8.765700017012396e+154\n",
      "Policy Evaluation iteration 156, delta: 5.878589878661358e+156\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 3.9007831654874344e+151 8.678043016842261e+155\n",
      "Policy Evaluation iteration 157, delta: 5.819803979874747e+157\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 3.8617753338325654e+152 8.59126258667383e+156\n",
      "Policy Evaluation iteration 158, delta: 5.761605940076001e+158\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 3.823157580494242e+153 8.505349960807102e+157\n",
      "Policy Evaluation iteration 159, delta: 5.703989880675239e+159\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 3.7849260046892995e+154 8.420296461199028e+158\n",
      "Policy Evaluation iteration 160, delta: 5.646949981868488e+160\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 3.7470767446424003e+155 8.336093496587028e+159\n",
      "Policy Evaluation iteration 161, delta: 5.590480482049813e+161\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 3.7096059771959745e+156 8.252732561621163e+160\n",
      "Policy Evaluation iteration 162, delta: 5.534575677229296e+162\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 3.6725099174240146e+157 8.170205236004948e+161\n",
      "Policy Evaluation iteration 163, delta: 5.47922992045701e+163\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 3.635784818249776e+158 8.088503183644895e+162\n",
      "Policy Evaluation iteration 164, delta: 5.424437621252434e+164\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 3.5994269700672756e+159 8.007618151808445e+163\n",
      "Policy Evaluation iteration 165, delta: 5.370193245039918e+165\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 3.5634327003666004e+160 7.927541970290358e+164\n",
      "Policy Evaluation iteration 166, delta: 5.316491312589511e+166\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 3.5277983733629257e+161 7.848266550587464e+165\n",
      "Policy Evaluation iteration 167, delta: 5.263326399463614e+167\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 3.492520389629311e+162 7.769783885081588e+166\n",
      "Policy Evaluation iteration 168, delta: 5.21069313546899e+168\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 3.457595185733023e+163 7.692086046230767e+167\n",
      "Policy Evaluation iteration 169, delta: 5.158586204114301e+169\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 3.42301923387569e+164 7.61516518576847e+168\n",
      "Policy Evaluation iteration 170, delta: 5.107000342073166e+170\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 3.388789041536936e+165 7.539013533910786e+169\n",
      "Policy Evaluation iteration 171, delta: 5.055930338652436e+171\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 3.3549011511215743e+166 7.463623398571698e+170\n",
      "Policy Evaluation iteration 172, delta: 5.005371035265912e+172\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 3.3213521396103593e+167 7.388987164585981e+171\n",
      "Policy Evaluation iteration 173, delta: 4.955317324913258e+173\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 3.2881386182142516e+168 7.315097292940111e+172\n",
      "Policy Evaluation iteration 174, delta: 4.9057641516641265e+174\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 3.2552572320320975e+169 7.241946320010704e+173\n",
      "Policy Evaluation iteration 175, delta: 4.856706510147464e+175\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 3.2227046597117834e+170 7.169526856810597e+174\n",
      "Policy Evaluation iteration 176, delta: 4.808139445045991e+176\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 3.1904776131146563e+171 7.097831588242478e+175\n",
      "Policy Evaluation iteration 177, delta: 4.760058050595528e+177\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 3.15857283698351e+172 7.026853272360063e+176\n",
      "Policy Evaluation iteration 178, delta: 4.7124574700895755e+178\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 3.12698710861368e+173 6.956584739636467e+177\n",
      "Policy Evaluation iteration 179, delta: 4.6653328953886754e+179\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 3.0957172375275386e+174 6.887018892240094e+178\n",
      "Policy Evaluation iteration 180, delta: 4.618679566434788e+180\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 3.064760065152263e+175 6.818148703317694e+179\n",
      "Policy Evaluation iteration 181, delta: 4.572492770770442e+181\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 3.0341124645007405e+176 6.74996721628452e+180\n",
      "Policy Evaluation iteration 182, delta: 4.5267678430627435e+182\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 3.0037713398557444e+177 6.68246754412166e+181\n",
      "Policy Evaluation iteration 183, delta: 4.481500164632116e+183\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 2.9737336264571863e+178 6.615642868680454e+182\n",
      "Policy Evaluation iteration 184, delta: 4.436685162985798e+184\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 2.943996290192606e+179 6.549486439993665e+183\n",
      "Policy Evaluation iteration 185, delta: 4.392318311355938e+185\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 2.9145563272906846e+180 6.483991575593728e+184\n",
      "Policy Evaluation iteration 186, delta: 4.3483951282423843e+186\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 2.8854107640177856e+181 6.419151659837782e+185\n",
      "Policy Evaluation iteration 187, delta: 4.3049111769599655e+187\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 2.8565566563776094e+182 6.354960143239412e+186\n",
      "Policy Evaluation iteration 188, delta: 4.2618620651903516e+188\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 2.827991089813826e+183 6.291410541807003e+187\n",
      "Policy Evaluation iteration 189, delta: 4.21924344453846e+189\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 2.7997111789156898e+184 6.228496436388941e+188\n",
      "Policy Evaluation iteration 190, delta: 4.177051010093072e+190\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 2.7717140671265307e+185 6.166211472025055e+189\n",
      "Policy Evaluation iteration 191, delta: 4.1352804999921394e+191\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 2.743996926455269e+186 6.104549357304803e+190\n",
      "Policy Evaluation iteration 192, delta: 4.093927694992209e+192\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 2.716556957190709e+187 6.043503863731745e+191\n",
      "Policy Evaluation iteration 193, delta: 4.052988418042289e+193\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 2.6893913876187993e+188 5.983068825094407e+192\n",
      "Policy Evaluation iteration 194, delta: 4.0124585338618746e+194\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 2.6624974737426084e+189 5.923238136843467e+193\n",
      "Policy Evaluation iteration 195, delta: 3.972333948523248e+195\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 2.63587249900518e+190 5.864005755475024e+194\n",
      "Policy Evaluation iteration 196, delta: 3.932610609038018e+196\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 2.6095137740151278e+191 5.805365697920275e+195\n",
      "Policy Evaluation iteration 197, delta: 3.893284502947644e+197\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 2.5834186362749754e+192 5.747312040941061e+196\n",
      "Policy Evaluation iteration 198, delta: 3.854351657918163e+198\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 2.5575844499122213e+193 5.6898389205316516e+197\n",
      "Policy Evaluation iteration 199, delta: 3.815808141338971e+199\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 2.5320086054130987e+194 5.632940531326318e+198\n",
      "Policy Evaluation iteration 200, delta: 3.777650059925579e+200\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 2.5066885193589644e+195 5.576611126013068e+199\n",
      "Policy Evaluation iteration 201, delta: 3.7398735593263213e+201\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 2.481621634165379e+196 5.520845014752926e+200\n",
      "Policy Evaluation iteration 202, delta: 3.7024748237330486e+202\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 2.4568054178237204e+197 5.465636564605409e+201\n",
      "Policy Evaluation iteration 203, delta: 3.665450075495713e+203\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 2.4322373636454864e+198 5.410980198959349e+202\n",
      "Policy Evaluation iteration 204, delta: 3.628795574740756e+204\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 2.4079149900090307e+199 5.356870396969757e+203\n",
      "Policy Evaluation iteration 205, delta: 3.5925076189933507e+205\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 2.38383584010894e+200 5.303301693000049e+204\n",
      "Policy Evaluation iteration 206, delta: 3.556582542803406e+206\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 2.3599974817078414e+201 5.25026867607005e+205\n",
      "Policy Evaluation iteration 207, delta: 3.521016717375381e+207\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 2.3363975068907603e+202 5.197765989309347e+206\n",
      "Policy Evaluation iteration 208, delta: 3.4858065502016146e+208\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 2.3130335318218538e+203 5.145788329416255e+207\n",
      "Policy Evaluation iteration 209, delta: 3.4509484846996e+209\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 2.289903196503632e+204 5.094330446122089e+208\n",
      "Policy Evaluation iteration 210, delta: 3.4164389998526036e+210\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 2.2670041645385982e+205 5.043387141660872e+209\n",
      "Policy Evaluation iteration 211, delta: 3.3822746098540708e+211\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 2.244334122893214e+206 4.99295327024425e+210\n",
      "Policy Evaluation iteration 212, delta: 3.3484518637555362e+212\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 2.2218907816642815e+207 4.943023737541819e+211\n",
      "Policy Evaluation iteration 213, delta: 3.314967345117978e+213\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 2.1996718738476364e+208 4.893593500166381e+212\n",
      "Policy Evaluation iteration 214, delta: 3.281817671666792e+214\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 2.1776751551091606e+209 4.844657565164725e+213\n",
      "Policy Evaluation iteration 215, delta: 3.248999494950134e+215\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 2.1558984035580737e+210 4.796210989513074e+214\n",
      "Policy Evaluation iteration 216, delta: 3.2165095000006276e+216\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 2.13433941952249e+211 4.748248879617952e+215\n",
      "Policy Evaluation iteration 217, delta: 3.1843444050006177e+217\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 2.112996025327261e+212 4.700766390821767e+216\n",
      "Policy Evaluation iteration 218, delta: 3.1525009609506087e+218\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 2.091866065073987e+213 4.653758726913545e+217\n",
      "Policy Evaluation iteration 219, delta: 3.1209759513411036e+219\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 2.0709474044232472e+214 4.6072211396443996e+218\n",
      "Policy Evaluation iteration 220, delta: 3.089766191827689e+220\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 2.050237930379009e+215 4.561148928247964e+219\n",
      "Policy Evaluation iteration 221, delta: 3.0588685299094078e+221\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 2.029735551075223e+216 4.5155374389654767e+220\n",
      "Policy Evaluation iteration 222, delta: 3.028279844610315e+222\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 2.009438195564465e+217 4.4703820645758094e+221\n",
      "Policy Evaluation iteration 223, delta: 2.9979970461642133e+223\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1.9893438136088255e+218 4.4256782439300515e+222\n",
      "Policy Evaluation iteration 224, delta: 2.9680170757025713e+224\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1.9694503754727366e+219 4.3814214614907554e+223\n",
      "Policy Evaluation iteration 225, delta: 2.9383369049455446e+225\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1.9497558717180082e+220 4.337607246875848e+224\n",
      "Policy Evaluation iteration 226, delta: 2.908953535896085e+226\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1.9302583130008283e+221 4.29423117440709e+225\n",
      "Policy Evaluation iteration 227, delta: 2.8798640005371217e+227\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1.9109557298708188e+222 4.251288862663016e+226\n",
      "Policy Evaluation iteration 228, delta: 2.8510653605317502e+228\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1.8918461725721028e+223 4.208775974036388e+227\n",
      "Policy Evaluation iteration 229, delta: 2.8225547069264255e+229\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1.872927710846378e+224 4.1666882142960146e+228\n",
      "Policy Evaluation iteration 230, delta: 2.7943291598571617e+230\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1.8541984337379186e+225 4.125021332153055e+229\n",
      "Policy Evaluation iteration 231, delta: 2.7663858682585917e+231\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1.8356564494005374e+226 4.083771118831519e+230\n",
      "Policy Evaluation iteration 232, delta: 2.738722009576004e+232\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1.8172998849065315e+227 4.042933407643202e+231\n",
      "Policy Evaluation iteration 233, delta: 2.7113347894802395e+233\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1.7991268860574675e+228 4.0025040735667717e+232\n",
      "Policy Evaluation iteration 234, delta: 2.6842214415854436e+234\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1.7811356171968962e+229 3.9624790328311077e+233\n",
      "Policy Evaluation iteration 235, delta: 2.6573792271695876e+235\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1.7633242610249262e+230 3.922854242502797e+234\n",
      "Policy Evaluation iteration 236, delta: 2.6308054348978893e+236\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1.745691018414675e+231 3.8836257000777635e+235\n",
      "Policy Evaluation iteration 237, delta: 2.604497380548907e+237\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1.728234108230527e+232 3.8447894430769836e+236\n",
      "Policy Evaluation iteration 238, delta: 2.5784524067434209e+238\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1.7109517671482209e+233 3.8063415486461986e+237\n",
      "Policy Evaluation iteration 239, delta: 2.5526678826759846e+239\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1.6938422494767386e+234 3.768278133159739e+238\n",
      "Policy Evaluation iteration 240, delta: 2.5271412038492264e+240\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1.676903826981967e+235 3.7305953518281384e+239\n",
      "Policy Evaluation iteration 241, delta: 2.5018697918107435e+241\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1.6601347887121458e+236 3.693289398309858e+240\n",
      "Policy Evaluation iteration 242, delta: 2.47685109389262e+242\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1.6435334408250258e+237 3.656356504326763e+241\n",
      "Policy Evaluation iteration 243, delta: 2.4520825829536955e+243\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1.6270981064167768e+238 3.6197929392834897e+242\n",
      "Policy Evaluation iteration 244, delta: 2.427561757124158e+244\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1.6108271253526082e+239 3.583595009890651e+243\n",
      "Policy Evaluation iteration 245, delta: 2.403286139552921e+245\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1.5947188540990804e+240 3.54775905979174e+244\n",
      "Policy Evaluation iteration 246, delta: 2.379253278157393e+246\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1.578771665558086e+241 3.512281469193816e+245\n",
      "Policy Evaluation iteration 247, delta: 2.3554607453758142e+247\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1.5629839489025039e+242 3.477158654501875e+246\n",
      "Policy Evaluation iteration 248, delta: 2.3319061379220474e+248\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1.5473541094134783e+243 3.442387067956852e+247\n",
      "Policy Evaluation iteration 249, delta: 2.3085870765428238e+249\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1.5318805683193438e+244 3.4079631972772824e+248\n",
      "Policy Evaluation iteration 250, delta: 2.2855012057773952e+250\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1.516561762636149e+245 3.373883565304518e+249\n",
      "Policy Evaluation iteration 251, delta: 2.2626461937196257e+251\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1.5013961450097915e+246 3.340144729651472e+250\n",
      "Policy Evaluation iteration 252, delta: 2.2400197317824296e+252\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1.4863821835596944e+247 3.3067432823549615e+251\n",
      "Policy Evaluation iteration 253, delta: 2.217619534464608e+253\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1.4715183617240958e+248 3.2736758495314137e+252\n",
      "Policy Evaluation iteration 254, delta: 2.195443339119963e+254\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1.4568031781068562e+249 3.240939091036097e+253\n",
      "Policy Evaluation iteration 255, delta: 2.1734889057287652e+255\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1.4422351463257872e+250 3.208529700125733e+254\n",
      "Policy Evaluation iteration 256, delta: 2.1517540166714747e+256\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1.4278127948625237e+251 3.1764444031244767e+255\n",
      "Policy Evaluation iteration 257, delta: 2.13023647650475e+257\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1.4135346669139e+252 3.1446799590932306e+256\n",
      "Policy Evaluation iteration 258, delta: 2.1089341117397004e+258\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1.3993993202447582e+253 3.113233159502299e+257\n",
      "Policy Evaluation iteration 259, delta: 2.0878447706223114e+259\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1.3854053270423106e+254 3.082100827907276e+258\n",
      "Policy Evaluation iteration 260, delta: 2.0669663229160786e+260\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1.3715512737718849e+255 3.051279819628198e+259\n",
      "Policy Evaluation iteration 261, delta: 2.046296659686916e+261\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1.3578357610341648e+256 3.0207670214319174e+260\n",
      "Policy Evaluation iteration 262, delta: 2.0258336930900483e+262\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1.3442574034238254e+257 2.9905593512176004e+261\n",
      "Policy Evaluation iteration 263, delta: 2.005575356159145e+263\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1.330814829389583e+258 2.9606537577054195e+262\n",
      "Policy Evaluation iteration 264, delta: 1.9855196025975558e+264\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1.317506681095687e+259 2.931047220128363e+263\n",
      "Policy Evaluation iteration 265, delta: 1.9656644065715802e+265\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1.3043316142847328e+260 2.901736747927083e+264\n",
      "Policy Evaluation iteration 266, delta: 1.9460077625058627e+266\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1.2912882981418838e+261 2.872719380447813e+265\n",
      "Policy Evaluation iteration 267, delta: 1.9265476848808034e+267\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1.2783754151604663e+262 2.8439921866433285e+266\n",
      "Policy Evaluation iteration 268, delta: 1.907282208031995e+268\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1.2655916610088592e+263 2.815552264776899e+267\n",
      "Policy Evaluation iteration 269, delta: 1.8882093859516763e+269\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1.25293574439877e+264 2.787396742129132e+268\n",
      "Policy Evaluation iteration 270, delta: 1.869327292092157e+270\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1.240406386954784e+265 2.7595227747078374e+269\n",
      "Policy Evaluation iteration 271, delta: 1.8506340191712342e+271\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1.228002323085237e+266 2.7319275469607553e+270\n",
      "Policy Evaluation iteration 272, delta: 1.8321276789795223e+272\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1.215722299854384e+267 2.7046082714911443e+271\n",
      "Policy Evaluation iteration 273, delta: 1.8138064021897258e+273\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1.2035650768558392e+268 2.6775621887762342e+272\n",
      "Policy Evaluation iteration 274, delta: 1.7956683381678282e+274\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1.1915294260872784e+269 2.6507865668884733e+273\n",
      "Policy Evaluation iteration 275, delta: 1.777711654786152e+275\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1.1796141318264067e+270 2.624278701219587e+274\n",
      "Policy Evaluation iteration 276, delta: 1.7599345382382896e+276\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1.1678179905081428e+271 2.5980359142073942e+275\n",
      "Policy Evaluation iteration 277, delta: 1.7423351928559097e+277\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1.1561398106030629e+272 2.572055555065324e+276\n",
      "Policy Evaluation iteration 278, delta: 1.7249118409273516e+278\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1.1445784124970325e+273 2.546334999514673e+277\n",
      "Policy Evaluation iteration 279, delta: 1.70766272251808e+279\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1.133132628372064e+274 2.5208716495195297e+278\n",
      "Policy Evaluation iteration 280, delta: 1.690586095292905e+280\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1.1218013020883467e+275 2.495662933024339e+279\n",
      "Policy Evaluation iteration 281, delta: 1.6736802343399703e+281\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1.1105832890674608e+276 2.47070630369409e+280\n",
      "Policy Evaluation iteration 282, delta: 1.65694343199657e+282\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1.0994774561767853e+277 2.4459992406571496e+281\n",
      "Policy Evaluation iteration 283, delta: 1.6403739976766045e+283\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1.0884826816150186e+278 2.4215392482505777e+282\n",
      "Policy Evaluation iteration 284, delta: 1.6239702576998375e+284\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1.0775978547988665e+279 2.3973238557680703e+283\n",
      "Policy Evaluation iteration 285, delta: 1.6077305551228379e+285\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1.0668218762508749e+280 2.3733506172103864e+284\n",
      "Policy Evaluation iteration 286, delta: 1.591653249571609e+286\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1.0561536574883657e+281 2.3496171110382838e+285\n",
      "Policy Evaluation iteration 287, delta: 1.5757367170758888e+287\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1.0455921209134817e+282 2.3261209399278908e+286\n",
      "Policy Evaluation iteration 288, delta: 1.5599793499051294e+288\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1.0351361997043471e+283 2.302859730528615e+287\n",
      "Policy Evaluation iteration 289, delta: 1.5443795564060769e+289\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1.0247848377073012e+284 2.2798311332233276e+288\n",
      "Policy Evaluation iteration 290, delta: 1.528935760842017e+290\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1.0145369893302272e+285 2.2570328218910947e+289\n",
      "Policy Evaluation iteration 291, delta: 1.513646403233591e+291\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 1.0043916194369258e+286 2.234462493672176e+290\n",
      "Policy Evaluation iteration 292, delta: 1.4985099392012548e+292\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 9.943477032425573e+286 2.2121178687354535e+291\n",
      "Policy Evaluation iteration 293, delta: 1.4835248398092401e+293\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 9.84404226210129e+287 2.1899966900480964e+292\n",
      "Policy Evaluation iteration 294, delta: 1.4686895914111483e+294\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 9.745601839480267e+288 2.168096723147616e+293\n",
      "Policy Evaluation iteration 295, delta: 1.4540026954970358e+295\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 9.648145821085448e+289 2.1464157559161354e+294\n",
      "Policy Evaluation iteration 296, delta: 1.4394626685420622e+296\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 9.55166436287458e+290 2.1249515983569717e+295\n",
      "Policy Evaluation iteration 297, delta: 1.4250680418566435e+297\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 9.456147719245857e+291 2.1037020823734005e+296\n",
      "Policy Evaluation iteration 298, delta: 1.4108173614380812e+298\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 9.361586242053387e+292 2.082665061549676e+297\n",
      "Policy Evaluation iteration 299, delta: 1.3967091878236987e+299\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 9.267970379632854e+293 2.061838410934178e+298\n",
      "Policy Evaluation iteration 300, delta: 1.3827420959454623e+300\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 9.175290675836552e+294 2.0412200268248372e+299\n",
      "Policy Evaluation iteration 301, delta: 1.368914674986006e+301\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 9.083537769078187e+295 2.0208078265565795e+300\n",
      "Policy Evaluation iteration 302, delta: 1.3552255282361426e+302\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 8.99270239138738e+296 2.0005997482910135e+301\n",
      "Policy Evaluation iteration 303, delta: 1.3416732729537821e+303\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 8.902775367473516e+297 1.9805937508081013e+302\n",
      "Policy Evaluation iteration 304, delta: 1.328256540224243e+304\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 8.813747613798772e+298 1.960787813300017e+303\n",
      "Policy Evaluation iteration 305, delta: 1.3149739748220013e+305\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 8.725610137660783e+299 1.9411799351670206e+304\n",
      "Policy Evaluation iteration 306, delta: 1.3018242350737825e+306\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 8.638354036284158e+300 1.9217681358153472e+305\n",
      "Policy Evaluation iteration 307, delta: 1.2888059927230446e+307\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 8.551970495921289e+301 1.902550454457189e+306\n",
      "Policy Evaluation iteration 308, delta: 1.2759179327958096e+308\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: 8.466450790962069e+302 1.8835249499126191e+307\n",
      "Policy Evaluation iteration 309, delta: inf\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 310, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 311, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 312, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 313, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 314, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 315, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24652/485955290.py:284: RuntimeWarning: invalid value encountered in subtract\n",
      "  delta = np.max(np.abs(old_V - self.V))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 316, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 317, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 318, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 319, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 320, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 321, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 322, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 323, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 324, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 325, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 326, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 327, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 328, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 329, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 330, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 331, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 332, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 333, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 334, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 335, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 336, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 337, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 338, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 339, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 340, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 341, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 342, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 343, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 344, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 345, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 346, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 347, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 348, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 349, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 350, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 351, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 352, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 353, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 354, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 355, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 356, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 357, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 358, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 359, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 360, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 361, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 362, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 363, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 364, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 365, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 366, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 367, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 368, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 369, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 370, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 371, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 372, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 373, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 374, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 375, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 376, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 377, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 378, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 379, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 380, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 381, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 382, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 383, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 384, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 385, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 386, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 387, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 388, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 389, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 390, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 391, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 392, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 393, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 394, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 395, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 396, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 397, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 398, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 399, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 400, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 401, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 402, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 403, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 404, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 405, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 406, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 407, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 408, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 409, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 410, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 411, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 412, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 413, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 414, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 415, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 416, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 417, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 418, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 419, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 420, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 421, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 422, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 423, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 424, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 425, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 426, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 427, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 428, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 429, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 430, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 431, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 432, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 433, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 434, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 435, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 436, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 437, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 438, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 439, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 440, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 441, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 442, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 443, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 444, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 445, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 446, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 447, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 448, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 449, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 450, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 451, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 452, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 453, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 454, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 455, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 456, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 457, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 458, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 459, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 460, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 461, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 462, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 463, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 464, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 465, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 466, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 467, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 468, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 469, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 470, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 471, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 472, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 473, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 474, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 475, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 476, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 477, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 478, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 479, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 480, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 481, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 482, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 483, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 484, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 485, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 486, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 487, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 488, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 489, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 490, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 491, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 492, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 493, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 494, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 495, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 496, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 497, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 498, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 499, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 500, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 501, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 502, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 503, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 504, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 505, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 506, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 507, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 508, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 509, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 510, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 511, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 512, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 513, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 514, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 515, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 516, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 517, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 518, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 519, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 520, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 521, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 522, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 523, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 524, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 525, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 526, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 527, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 528, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 529, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 530, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 531, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 532, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 533, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 534, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 535, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 536, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 537, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 538, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 539, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 540, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 541, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 542, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 543, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 544, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 545, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 546, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 547, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 548, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 549, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 550, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 551, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 552, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 553, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 554, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 555, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 556, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 557, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 558, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 559, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 560, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 561, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 562, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 563, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 564, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 565, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 566, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 567, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 568, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 569, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 570, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 571, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 572, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 573, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 574, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 575, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 576, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 577, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 578, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 579, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 580, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 581, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 582, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 583, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 584, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 585, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 586, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 587, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 588, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 589, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 590, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 591, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 592, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 593, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 594, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 595, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 596, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 597, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 598, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 599, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 600, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 601, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 602, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 603, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 604, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 605, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 606, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 607, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 608, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 609, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 610, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 611, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 612, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 613, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 614, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 615, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 616, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 617, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 618, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 619, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 620, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 621, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 622, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 623, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 624, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 625, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 626, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 627, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 628, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 629, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 630, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 631, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 632, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 633, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 634, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 635, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 636, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 637, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 638, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 639, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 640, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 641, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 642, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 643, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 644, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 645, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 646, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 647, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 648, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 649, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 650, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 651, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 652, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 653, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 654, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 655, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 656, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 657, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 658, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 659, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 660, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 661, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 662, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 663, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 664, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 665, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 666, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 667, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 668, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 669, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 670, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 671, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 672, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 673, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 674, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 675, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 676, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 677, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 678, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 679, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 680, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 681, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 682, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 683, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 684, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 685, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 686, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 687, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 688, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 689, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 690, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 691, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 692, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 693, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 694, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 695, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 696, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 697, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 698, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 699, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 700, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 701, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 702, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 703, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 704, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 705, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 706, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 707, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 708, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 709, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 710, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 711, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 712, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 713, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 714, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 715, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 716, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 717, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 718, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 719, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 720, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 721, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 722, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 723, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 724, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 725, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 726, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 727, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 728, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 729, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 730, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 731, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 732, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 733, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 734, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 735, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 736, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 737, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 738, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 739, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 740, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 741, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 742, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 743, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 744, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 745, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 746, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 747, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 748, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 749, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 750, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 751, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 752, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 753, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 754, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 755, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 756, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 757, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 758, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 759, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 760, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 761, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 762, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 763, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 764, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 765, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 766, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 767, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 768, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 769, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 770, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 771, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 772, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 773, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 774, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 775, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 776, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 777, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 778, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 779, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 780, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 781, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 782, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 783, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 784, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 785, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 786, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 787, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 788, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 789, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 790, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 791, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 792, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 793, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 794, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 795, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 796, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 797, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 798, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 799, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 800, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 801, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 802, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 803, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 804, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 805, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 806, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 807, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 808, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 809, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 810, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 811, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 812, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 813, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 814, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 815, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 816, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 817, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 818, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 819, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 820, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 821, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 822, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 823, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 824, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 825, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 826, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 827, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 828, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 829, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 830, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 831, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 832, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 833, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 834, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 835, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 836, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 837, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 838, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 839, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 840, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 841, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 842, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 843, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 844, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 845, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 846, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 847, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 848, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 849, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 850, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 851, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 852, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 853, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 854, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 855, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 856, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 857, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 858, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 859, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 860, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 861, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 862, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 863, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 864, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 865, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 866, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 867, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 868, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 869, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 870, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 871, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 872, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 873, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 874, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 875, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 876, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 877, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 878, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 879, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 880, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 881, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 882, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 883, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 884, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 885, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 886, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 887, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 888, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 889, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 890, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 891, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 892, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 893, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 894, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 895, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 896, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 897, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 898, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 899, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 900, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 901, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 902, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 903, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 904, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 905, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 906, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 907, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 908, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 909, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 910, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 911, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 912, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 913, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 914, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 915, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 916, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 917, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 918, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 919, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 920, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 921, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 922, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 923, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 924, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 925, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 926, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 927, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 928, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 929, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 930, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 931, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 932, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 933, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 934, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 935, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 936, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 937, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 938, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 939, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 940, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 941, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 942, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 943, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 944, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 945, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 946, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 947, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 948, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 949, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 950, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 951, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 952, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 953, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 954, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 955, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 956, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 957, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 958, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 959, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 960, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 961, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 962, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 963, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 964, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 965, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 966, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 967, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 968, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 969, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 970, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 971, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 972, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 973, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 974, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 975, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 976, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 977, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 978, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 979, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 980, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 981, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 982, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 983, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 984, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 985, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 986, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 987, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 988, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 989, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 990, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 991, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 992, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 993, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 994, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 995, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 996, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 997, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 998, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 999, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1000, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1001, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1002, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1003, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1004, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1005, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1006, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1007, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1008, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1009, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1010, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1011, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1012, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1013, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1014, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1015, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1016, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1017, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1018, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1019, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1020, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1021, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1022, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1023, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1024, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1025, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1026, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1027, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1028, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1029, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1030, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1031, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1032, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1033, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1034, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1035, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1036, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1037, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1038, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1039, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1040, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1041, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1042, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1043, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1044, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1045, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1046, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1047, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1048, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1049, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1050, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1051, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1052, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1053, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1054, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1055, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1056, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1057, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1058, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1059, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1060, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1061, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1062, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1063, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1064, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1065, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1066, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1067, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1068, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1069, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1070, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1071, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1072, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1073, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1074, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1075, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1076, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1077, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1078, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1079, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1080, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1081, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1082, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1083, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1084, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1085, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1086, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1087, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1088, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1089, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1090, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1091, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1092, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1093, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1094, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1095, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1096, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1097, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1098, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1099, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1100, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1101, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1102, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1103, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1104, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1105, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1106, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1107, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1108, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1109, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1110, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1111, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1112, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1113, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1114, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1115, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1116, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1117, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1118, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1119, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1120, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1121, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1122, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1123, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1124, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1125, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1126, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1127, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1128, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1129, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1130, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1131, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1132, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1133, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1134, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1135, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1136, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1137, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1138, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1139, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1140, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1141, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1142, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1143, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1144, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1145, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1146, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1147, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1148, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1149, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1150, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1151, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1152, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1153, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1154, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1155, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1156, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1157, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1158, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1159, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1160, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1161, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1162, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1163, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1164, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1165, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1166, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1167, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1168, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1169, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1170, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1171, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1172, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1173, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1174, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1175, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1176, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1177, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1178, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1179, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1180, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1181, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1182, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1183, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1184, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1185, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1186, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1187, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1188, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1189, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1190, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1191, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1192, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1193, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1194, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1195, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1196, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1197, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1198, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1199, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1200, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1201, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1202, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1203, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1204, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1205, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1206, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1207, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1208, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1209, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1210, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1211, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1212, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1213, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1214, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1215, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1216, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1217, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1218, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1219, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1220, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1221, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1222, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1223, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1224, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1225, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1226, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1227, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1228, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1229, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1230, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1231, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1232, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1233, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1234, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1235, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1236, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1237, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1238, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1239, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1240, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1241, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1242, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1243, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1244, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1245, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1246, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1247, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1248, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1249, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1250, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1251, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1252, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1253, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1254, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1255, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1256, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1257, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1258, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1259, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1260, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1261, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1262, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1263, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1264, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1265, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1266, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1267, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1268, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1269, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1270, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1271, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1272, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1273, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1274, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1275, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1276, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1277, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1278, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1279, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1280, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1281, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1282, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1283, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1284, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1285, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1286, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1287, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1288, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1289, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1290, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1291, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1292, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1293, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1294, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1295, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1296, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1297, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1298, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1299, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1300, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1301, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1302, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1303, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1304, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1305, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1306, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1307, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1308, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1309, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1310, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1311, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1312, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1313, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1314, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1315, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1316, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1317, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1318, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1319, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1320, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1321, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1322, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1323, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1324, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1325, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1326, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1327, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1328, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1329, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1330, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1331, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1332, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1333, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1334, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1335, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1336, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1337, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1338, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1339, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1340, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1341, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1342, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1343, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1344, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1345, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1346, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1347, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1348, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1349, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1350, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1351, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1352, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1353, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1354, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1355, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1356, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1357, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1358, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1359, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1360, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1361, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1362, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1363, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1364, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1365, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1366, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1367, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1368, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1369, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1370, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1371, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1372, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1373, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1374, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1375, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1376, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1377, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1378, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1379, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1380, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1381, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1382, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1383, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1384, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1385, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1386, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1387, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1388, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1389, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1390, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1391, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1392, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1393, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1394, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1395, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1396, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1397, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1398, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1399, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1400, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1401, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1402, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1403, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1404, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1405, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1406, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1407, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1408, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1409, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1410, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1411, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1412, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1413, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1414, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1415, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1416, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1417, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1418, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1419, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1420, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1421, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1422, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1423, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1424, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1425, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1426, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1427, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1428, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1429, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1430, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1431, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1432, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1433, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1434, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1435, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1436, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1437, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1438, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1439, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1440, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1441, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1442, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1443, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1444, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1445, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1446, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1447, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1448, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1449, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1450, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1451, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1452, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1453, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1454, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1455, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1456, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1457, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1458, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1459, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1460, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1461, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1462, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1463, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1464, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1465, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1466, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1467, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1468, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1469, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1470, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1471, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1472, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1473, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1474, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1475, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1476, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1477, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1478, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1479, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1480, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1481, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1482, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1483, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1484, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1485, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1486, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1487, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1488, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1489, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1490, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1491, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1492, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1493, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1494, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1495, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1496, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1497, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1498, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1499, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1500, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1501, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1502, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1503, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1504, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1505, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1506, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1507, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1508, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1509, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1510, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1511, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1512, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1513, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1514, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1515, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1516, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1517, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1518, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1519, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1520, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1521, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1522, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1523, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1524, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1525, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1526, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1527, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1528, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1529, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1530, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n",
      "Expected values range: inf inf\n",
      "Policy Evaluation iteration 1531, delta: nan\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 4850.999999999998\n",
      "Probability range: 6.628128960450627e-06 0.14745548726951835\n",
      "Total rewards range: -10 110\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m original_problem \u001b[38;5;241m=\u001b[39m TensorState()\n\u001b[0;32m----> 2\u001b[0m \u001b[43moriginal_problem\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy_iteration\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[23], line 392\u001b[0m, in \u001b[0;36mTensorState.policy_iteration\u001b[0;34m(self, theta, gamma)\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[38;5;66;03m# Policy Evaluation\u001b[39;00m\n\u001b[1;32m    391\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPolicy Evaluation...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 392\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy_evaluation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtheta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgamma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    394\u001b[0m \u001b[38;5;66;03m# Policy Improvement\u001b[39;00m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPolicy Improvement...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[23], line 262\u001b[0m, in \u001b[0;36mTensorState.policy_evaluation\u001b[0;34m(self, theta, gamma)\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal rewards range:\u001b[39m\u001b[38;5;124m\"\u001b[39m, np\u001b[38;5;241m.\u001b[39mmin(total_rewards), np\u001b[38;5;241m.\u001b[39mmax(total_rewards))\n\u001b[1;32m    261\u001b[0m \u001b[38;5;66;03m# Get next states\u001b[39;00m\n\u001b[0;32m--> 262\u001b[0m next_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalculate_next_states\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalid_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpost_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# Calculate next state values\u001b[39;00m\n\u001b[1;32m    265\u001b[0m next_state_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mV[next_states[:, \u001b[38;5;241m0\u001b[39m], next_states[:, \u001b[38;5;241m1\u001b[39m]]\n",
      "Cell \u001b[0;32mIn[23], line 230\u001b[0m, in \u001b[0;36mTensorState.calculate_next_states\u001b[0;34m(self, valid_indices, post_states)\u001b[0m\n\u001b[1;32m    227\u001b[0m next_cars2 \u001b[38;5;241m=\u001b[39m post_cars2 \u001b[38;5;241m-\u001b[39m rentals2 \u001b[38;5;241m+\u001b[39m returns2\n\u001b[1;32m    229\u001b[0m \u001b[38;5;66;03m# Stack into single array\u001b[39;00m\n\u001b[0;32m--> 230\u001b[0m next_states \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnext_cars1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnext_cars2\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m next_states\n",
      "File \u001b[0;32m~/projects/barto-and-sutton/.venv/lib/python3.10/site-packages/numpy/_core/shape_base.py:367\u001b[0m, in \u001b[0;36m_stack_dispatcher\u001b[0;34m(arrays, axis, out, dtype, casting)\u001b[0m\n\u001b[1;32m    363\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    364\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _nx\u001b[38;5;241m.\u001b[39mconcatenate(arrs, \u001b[38;5;241m1\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mdtype, casting\u001b[38;5;241m=\u001b[39mcasting)\n\u001b[0;32m--> 367\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_stack_dispatcher\u001b[39m(arrays, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m    368\u001b[0m                       dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, casting\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    369\u001b[0m     arrays \u001b[38;5;241m=\u001b[39m _arrays_for_stack_dispatcher(arrays)\n\u001b[1;32m    370\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    371\u001b[0m         \u001b[38;5;66;03m# optimize for the typical case where only arrays is provided\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "original_problem = TensorState()\n",
    "original_problem.policy_iteration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
