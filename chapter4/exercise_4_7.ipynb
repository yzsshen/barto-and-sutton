{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4.7\n",
    "\n",
    "Write a program for policy iteration and re-solve Jack’s car rental problem with the following changes.\n",
    "\n",
    "One of Jack’s employees at the first location rides a bus home each night and lives near the second location. \n",
    "\n",
    "She is happy to shuttle one car to the second location for free. \n",
    "\n",
    "Each additional car still costs $2, as do all cars moved in the other direction. \n",
    "\n",
    "In addition, Jack has limited parking space at each location. \n",
    "\n",
    "If more than 10 cars are kept overnight at a location (after any moving of cars), then an additional cost of $4 must be incurred to use a second parking lot (independent of how many cars are kept there). \n",
    "\n",
    "These sorts of nonlinearities and arbitrary dynamics often occur in real problems and cannot easily be handled by optimization methods other than dynamic programming. To check your program, first replicate the results given for the original problem.\n",
    "\n",
    "![Jack's car rental problem](ex4.2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing_extensions import Self\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "from scipy.stats import poisson\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create State class\n",
    "@dataclass\n",
    "class State:\n",
    "    cars_loc1: int\n",
    "    cars_loc2: int\n",
    "    \n",
    "    def __hash__(self) -> int:\n",
    "        return hash((self.cars_loc1, self.cars_loc2))\n",
    "    \n",
    "    def __eq__(self, other) -> bool:\n",
    "        if not isinstance(other, State):\n",
    "            return False\n",
    "        return (self.cars_loc1 == other.cars_loc1 and \n",
    "                self.cars_loc2 == other.cars_loc2)\n",
    "    \n",
    "    def __post_init__(self) -> None:\n",
    "        assert (0 <= self.cars_loc1 <= 20 and 0 <= self.cars_loc2 <= 20), \"Cars at each location must be between 0 and 20\"\n",
    "        \n",
    "    def move_cars(self, cars_moved_l1_to_l2: int) -> tuple[Self, int]:\n",
    "        assert (-5 <= cars_moved_l1_to_l2 <= 5), \"Actions can only move up to 5 cars\"\n",
    "        assert (cars_moved_l1_to_l2 <= self.cars_loc1 and -cars_moved_l1_to_l2 <= self.cars_loc2), \"Cannot move more cars than there are at the location\"\n",
    "        \n",
    "        reward = -2 * np.abs(cars_moved_l1_to_l2)\n",
    "        \n",
    "        return State(\n",
    "            cars_loc1=self.cars_loc1-cars_moved_l1_to_l2, \n",
    "            cars_loc2=self.cars_loc2+cars_moved_l1_to_l2,\n",
    "            ), reward\n",
    "    \n",
    "    @staticmethod\n",
    "    def poisson_prob(n: int, lambda_: int) -> float:\n",
    "        return (lambda_**n / math.factorial(n)) * np.exp(-lambda_)\n",
    "\n",
    "    def rent_car(self, location: int, rented_cars: int) -> tuple[Self, float, int]:\n",
    "        match location:\n",
    "            case 1:\n",
    "                cars_available: int = self.cars_loc1\n",
    "            case 2:\n",
    "                cars_available:int = self.cars_loc2\n",
    "        \n",
    "        assert 0 <= rented_cars <= cars_available, \"Cannot rent more cars than are available\"\n",
    "        \n",
    "        reward = 10 * rented_cars\n",
    "        \n",
    "        match location:\n",
    "            case 1:\n",
    "                return State(\n",
    "                    cars_loc1=self.cars_loc1-rented_cars, \n",
    "                    cars_loc2=self.cars_loc2,\n",
    "                    )\n",
    "            case 2:\n",
    "                return State(\n",
    "                    cars_loc1=self.cars_loc1, \n",
    "                    cars_loc2=self.cars_loc2-rented_cars,)\n",
    "    \n",
    "    def return_car(self, location: int, returned_cars: int) -> tuple[Self, float]:\n",
    "        match location:\n",
    "            case 1:\n",
    "                cars_available: int = self.cars_loc1\n",
    "            case 2:\n",
    "                cars_available:int = self.cars_loc2\n",
    "        \n",
    "        assert 20 >= returned_cars + cars_available, \"Cannot have than 20 cars in parking lot\"\n",
    "        \n",
    "        match location:\n",
    "            case 1:\n",
    "                return State(\n",
    "                    cars_loc1=self.cars_loc1+returned_cars, \n",
    "                    cars_loc2=self.cars_loc2,)\n",
    "            case 2:\n",
    "                return State(\n",
    "                    cars_loc1=self.cars_loc1, \n",
    "                    cars_loc2=self.cars_loc2+returned_cars,)\n",
    "    \n",
    "    def get_all_transitions(self, action: int) -> list[tuple[Self, float, int]]:\n",
    "        \"\"\"\n",
    "        Returns list of (next_state, probability, reward) for all possible transitions\n",
    "        given an action.\n",
    "        \"\"\"\n",
    "        # 1. Move cars overnight\n",
    "        next_state, move_reward = self.move_cars(action)\n",
    "        \n",
    "        transitions = []\n",
    "        # 2. Iterate over all possible combinations:\n",
    "        for rentals_loc1 in range(next_state.cars_loc1+1):\n",
    "            max_returns_loc1 = 20 - (next_state.cars_loc1 - rentals_loc1)\n",
    "            for returns_loc1 in range(max_returns_loc1 + 1):\n",
    "                for rentals_loc2 in range(next_state.cars_loc2 + 1):\n",
    "                    max_returns_loc2 = 20 - (next_state.cars_loc2 - rentals_loc2)\n",
    "                    for returns_loc2 in range(max_returns_loc2 + 1):\n",
    "                        if not (0 <= rentals_loc1 <= next_state.cars_loc1):\n",
    "                            continue\n",
    "                        elif not (0 <= rentals_loc2 <= next_state.cars_loc2):\n",
    "                            continue\n",
    "                        elif not (0 <= next_state.cars_loc1 - rentals_loc1 + returns_loc1 <= 20):\n",
    "                            continue\n",
    "                        elif not (0 <= next_state.cars_loc2 - rentals_loc2 + returns_loc2 <= 20):\n",
    "                            continue\n",
    "                        \n",
    "                        final_state = State(\n",
    "                            cars_loc1=next_state.cars_loc1 - rentals_loc1 + returns_loc1,\n",
    "                            cars_loc2=next_state.cars_loc2 - rentals_loc2 + returns_loc2,)\n",
    "                        \n",
    "                        # Check if valid state\n",
    "                        try:\n",
    "                            final_state.__post_init__()\n",
    "                        except ValueError:\n",
    "                            continue\n",
    "                            \n",
    "                        # Calculate probabilities\n",
    "                        rent_loc1_prob: float = self.poisson_prob(rentals_loc1, 3)\n",
    "                        return_loc1_prob: float = self.poisson_prob(returns_loc1, 3)\n",
    "                        rent_loc2_prob: float = self.poisson_prob(rentals_loc2, 4)\n",
    "                        return_loc2_prob: float = self.poisson_prob(returns_loc2, 2)\n",
    "                        \n",
    "                        probability: float = rent_loc1_prob * return_loc1_prob * rent_loc2_prob * return_loc2_prob\n",
    "                        reward: int = move_reward + 10 * (rentals_loc1 + rentals_loc2)\n",
    "                        \n",
    "                        transitions.append((final_state, probability, reward))\n",
    "                        \n",
    "        return transitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for Policy Iteration for original State class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize\n",
    "def initialize() -> tuple[dict, dict]:\n",
    "    # Initialize V(s) and pi(s) arbitrarily for all s in S\n",
    "    V: dict[State, float] = {}\n",
    "    policy: dict[State, int] = {}\n",
    "    \n",
    "    # All possible states\n",
    "    for cars_loc1 in range(21):\n",
    "        for cars_loc2 in range(21):\n",
    "            state = State(cars_loc1, cars_loc2)\n",
    "            V[state] = 0 # arbitrary\n",
    "            policy[state] = 0 # don't move cars (arbitrary)\n",
    "    \n",
    "    return V, policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Policy Evaluation\n",
    "def policy_evaluation(V: dict, policy: dict, theta: float=0.01, gamma: float=0.9) -> tuple[dict, dict]:\n",
    "    eval_iteration = 0\n",
    "    while True:\n",
    "        delta = 0\n",
    "        # Loop through states\n",
    "        for state in V:\n",
    "            v = V[state]\n",
    "            \n",
    "            # Get transitions for current policy\n",
    "            transitions = state.get_all_transitions(policy[state])\n",
    "            \n",
    "            # Set new V based on update equation\n",
    "            V[state] = sum(prob * (reward + gamma * V[next_state]) for next_state, prob, reward in transitions)\n",
    "            \n",
    "            # Set Delta\n",
    "            delta = max(delta, np.abs(v - V[state]))\n",
    "        \n",
    "        eval_iteration += 1\n",
    "        print(f\"Policy Evaluation iteration {eval_iteration}, delta: {delta}\")\n",
    "        \n",
    "        # Check if Delta less than theta\n",
    "        if delta < theta:\n",
    "            break\n",
    "        \n",
    "    return V, policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Policy Improvement\n",
    "def policy_improvement(V: dict, policy: dict, gamma: float=0.9) -> tuple[dict, dict, bool]:\n",
    "    policy_stable = True\n",
    "    action_changes = 0\n",
    "    \n",
    "    # Loop through states\n",
    "    for state in V:\n",
    "        # Set old action\n",
    "        old_action = policy[state]\n",
    "        \n",
    "        # Calculate value under current policy\n",
    "        old_transitions = state.get_all_transitions(old_action)\n",
    "        current_value = sum(prob * (reward + gamma * V[next_state]) for next_state, prob, reward in old_transitions)\n",
    "        \n",
    "        # Find best action\n",
    "        best_value = float('-inf')\n",
    "        best_action = old_action\n",
    "        \n",
    "        for action in range(-5, 6):\n",
    "            try:\n",
    "                # Get all transitions for this action\n",
    "                transitions = state.get_all_transitions(action)\n",
    "            except AssertionError:\n",
    "                # Skip invalid actions\n",
    "                continue\n",
    "            \n",
    "                            \n",
    "            # Calculate value of the action\n",
    "            action_value = sum(prob * (reward + gamma * V[next_state]) for next_state, prob, reward in transitions)\n",
    "            \n",
    "            # Update if value is better\n",
    "            if action_value > best_value:\n",
    "                best_value = action_value\n",
    "                best_action = action\n",
    "            \n",
    "        # Update policy if there is a better action\n",
    "        if best_value > current_value:\n",
    "            policy[state] = best_action\n",
    "            if old_action != best_action:\n",
    "                action_changes += 1\n",
    "                policy_stable = False\n",
    "    \n",
    "    print(f\"Number of policy changes: {action_changes}\")\n",
    "    return V, policy, policy_stable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_value_policy(V, policy):\n",
    "    # Create meshgrid of states\n",
    "    X, Y = np.meshgrid(range(21), range(21))\n",
    "    values = np.zeros((21, 21))\n",
    "    actions = np.zeros((21, 21))\n",
    "    \n",
    "    for i in range(21):\n",
    "        for j in range(21):\n",
    "            state = State(i, j)\n",
    "            values[i,j] = V[state]\n",
    "            actions[i,j] = policy[state]\n",
    "    \n",
    "    # Plot values\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    plt.subplot(121)\n",
    "    plt.imshow(values, origin='lower')\n",
    "    plt.colorbar(label='Value')\n",
    "    plt.title('State Values')\n",
    "    plt.xlabel('Cars at Location 2')\n",
    "    plt.ylabel('Cars at Location 1')\n",
    "    plt.xticks(range(0, 21, 5))\n",
    "    plt.yticks(range(0, 21, 5))\n",
    "    \n",
    "    # Plot policy\n",
    "    plt.subplot(122)\n",
    "    plt.imshow(actions, origin='lower')\n",
    "    plt.colorbar(label='Action')\n",
    "    plt.title('Policy (cars to move)')\n",
    "    plt.xlabel('Cars at Location 2')\n",
    "    plt.ylabel('Cars at Location 1')\n",
    "    plt.xticks(range(0, 21, 5))\n",
    "    plt.yticks(range(0, 21, 5))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Policy Iteration Loop\n",
    "def policy_iteration(theta: float=0.01, gamma: float=0.9) -> tuple[dict, dict]:\n",
    "    # 1. Initialization\n",
    "    V, policy = initialize()\n",
    "    iteration = 0\n",
    "    \n",
    "    while True:\n",
    "        iteration += 1\n",
    "        print(f\"Iteration {iteration}\")\n",
    "        \n",
    "        # 2. Policy Evaluation\n",
    "        print(f\"Policy Evaluation...\")\n",
    "        V, policy = policy_evaluation(V, policy, theta, gamma)\n",
    "        \n",
    "        # 3. Policy Improvement\n",
    "        print(f\"Policy Improvement...\")\n",
    "        V, policy, policy_stable = policy_improvement(V, policy, gamma)\n",
    "        \n",
    "        if policy_stable:\n",
    "            print(f'Policy is stable!')\n",
    "            break\n",
    "        \n",
    "    return V, policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Policy Iteration Sequential Run\n",
    "This took about 2 hours to run, so I will try to parallelize it by vectorizing our operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1\n",
      "Policy Evaluation...\n",
      "Policy Evaluation iteration 1, delta: 128.68143159150108\n",
      "Policy Evaluation iteration 2, delta: 88.9840515410105\n",
      "Policy Evaluation iteration 3, delta: 55.05565782565117\n",
      "Policy Evaluation iteration 4, delta: 30.814137257998027\n",
      "Policy Evaluation iteration 5, delta: 15.799621724498763\n",
      "Policy Evaluation iteration 6, delta: 7.536976059132769\n",
      "Policy Evaluation iteration 7, delta: 3.3714427480243785\n",
      "Policy Evaluation iteration 8, delta: 1.4376409283248108\n",
      "Policy Evaluation iteration 9, delta: 0.5861307513773113\n",
      "Policy Evaluation iteration 10, delta: 0.2313577715176791\n",
      "Policy Evaluation iteration 11, delta: 0.0894852826085355\n",
      "Policy Evaluation iteration 12, delta: 0.033899597249046565\n",
      "Policy Evaluation iteration 13, delta: 0.012649625481003568\n",
      "Policy Evaluation iteration 14, delta: 0.004668615256775865\n",
      "Policy Improvement...\n",
      "Number of policy changes: 390\n",
      "Iteration 2\n",
      "Policy Evaluation...\n",
      "Policy Evaluation iteration 1, delta: 256.1086717133408\n",
      "Policy Evaluation iteration 2, delta: 40.34439528767007\n",
      "Policy Evaluation iteration 3, delta: 20.073966717865858\n",
      "Policy Evaluation iteration 4, delta: 12.691321563104395\n",
      "Policy Evaluation iteration 5, delta: 7.806876585815019\n",
      "Policy Evaluation iteration 6, delta: 4.57560453916949\n",
      "Policy Evaluation iteration 7, delta: 2.605864485380721\n",
      "Policy Evaluation iteration 8, delta: 1.457638081011055\n",
      "Policy Evaluation iteration 9, delta: 0.8057076099483425\n",
      "Policy Evaluation iteration 10, delta: 0.4429859454485836\n",
      "Policy Evaluation iteration 11, delta: 0.24203387348711658\n",
      "Policy Evaluation iteration 12, delta: 0.131742839393155\n",
      "Policy Evaluation iteration 13, delta: 0.07143916061886557\n",
      "Policy Evaluation iteration 14, delta: 0.03862967740411705\n",
      "Policy Evaluation iteration 15, delta: 0.020844445015029578\n",
      "Policy Evaluation iteration 16, delta: 0.011229849101709988\n",
      "Policy Evaluation iteration 17, delta: 0.006042868603913121\n",
      "Policy Improvement...\n",
      "Number of policy changes: 211\n",
      "Iteration 3\n",
      "Policy Evaluation...\n",
      "Policy Evaluation iteration 1, delta: 21.70599657058466\n",
      "Policy Evaluation iteration 2, delta: 8.753957624203451\n",
      "Policy Evaluation iteration 3, delta: 4.904676011211336\n",
      "Policy Evaluation iteration 4, delta: 2.738952871823983\n",
      "Policy Evaluation iteration 5, delta: 1.5241214588114644\n",
      "Policy Evaluation iteration 6, delta: 0.8458803218912863\n",
      "Policy Evaluation iteration 7, delta: 0.46719920519342395\n",
      "Policy Evaluation iteration 8, delta: 0.25722303032540594\n",
      "Policy Evaluation iteration 9, delta: 0.1412897242935287\n",
      "Policy Evaluation iteration 10, delta: 0.07747079895347042\n",
      "Policy Evaluation iteration 11, delta: 0.04241956502727362\n",
      "Policy Evaluation iteration 12, delta: 0.02320226418476068\n",
      "Policy Evaluation iteration 13, delta: 0.012680493599589227\n",
      "Policy Evaluation iteration 14, delta: 0.006925734515618842\n",
      "Policy Improvement...\n",
      "Number of policy changes: 24\n",
      "Iteration 4\n",
      "Policy Evaluation...\n",
      "Policy Evaluation iteration 1, delta: 0.6356164062266316\n",
      "Policy Evaluation iteration 2, delta: 0.04697723010468735\n",
      "Policy Evaluation iteration 3, delta: 0.024954606850371874\n",
      "Policy Evaluation iteration 4, delta: 0.015039013411978885\n",
      "Policy Evaluation iteration 5, delta: 0.00837289073285774\n",
      "Policy Improvement...\n",
      "Number of policy changes: 0\n",
      "Policy is stable!\n"
     ]
    }
   ],
   "source": [
    "# V, policy = policy_iteration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize_value_policy(V, policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changes to Jack's Rental Car Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModifiedState(State):\n",
    "    def get_all_transitions(self, action: int) -> list[tuple[Self, float, int]]:\n",
    "        transitions = super().get_all_transitions(action)\n",
    "        \n",
    "        # Adjust transition rewards based on the exercise\n",
    "        modified_transitions = []\n",
    "        \n",
    "        for state, prob, reward in transitions:\n",
    "            # Jack's employee moves a car from loc1 to loc2 for free\n",
    "            if action > 0:\n",
    "                reward += 2\n",
    "            \n",
    "            # If there are >10 cars in either lot, then Jack pays $4 for a secondary lot for the location\n",
    "            if state.cars_loc1 > 10:\n",
    "                reward -= 4\n",
    "            if state.cars_loc2 > 10:\n",
    "                reward -= 4\n",
    "            modified_transitions.append((state, prob, reward))\n",
    "            \n",
    "        return modified_transitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallelizing Original Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze Poisson to reduce the space for rentals and returns\n",
    "def poisson_pmf(k, lambda_):\n",
    "    return (lambda_**k / math.factorial(k)) * np.exp(-lambda_)\n",
    "\n",
    "def analyze_poisson(lambda_, name):\n",
    "    probs = []\n",
    "    cumsum = 0\n",
    "    print(f\"\\nAnalysis for {name} (lambda={lambda_}):\")\n",
    "    print(\"k\\tProb\\tCumulative\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    for k in range(15):\n",
    "        prob = poisson_pmf(k, lambda_)\n",
    "        cumsum += prob\n",
    "        print(f\"{k}\\t{prob:.6f}\\t{cumsum:.6f}\")\n",
    "        if cumsum > 0.998:\n",
    "            print(f\"99.8% of probability mass covered by k≤{k}\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analysis for rental1/return1 (lambda=3):\n",
      "k\tProb\tCumulative\n",
      "------------------------------\n",
      "0\t0.049787\t0.049787\n",
      "1\t0.149361\t0.199148\n",
      "2\t0.224042\t0.423190\n",
      "3\t0.224042\t0.647232\n",
      "4\t0.168031\t0.815263\n",
      "5\t0.100819\t0.916082\n",
      "6\t0.050409\t0.966491\n",
      "7\t0.021604\t0.988095\n",
      "8\t0.008102\t0.996197\n",
      "9\t0.002701\t0.998898\n",
      "99.8% of probability mass covered by k≤9\n"
     ]
    }
   ],
   "source": [
    "# Analyze each Poisson distribution\n",
    "analyze_poisson(3, \"rental1/return1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analysis for rental2 (lambda=4):\n",
      "k\tProb\tCumulative\n",
      "------------------------------\n",
      "0\t0.018316\t0.018316\n",
      "1\t0.073263\t0.091578\n",
      "2\t0.146525\t0.238103\n",
      "3\t0.195367\t0.433470\n",
      "4\t0.195367\t0.628837\n",
      "5\t0.156293\t0.785130\n",
      "6\t0.104196\t0.889326\n",
      "7\t0.059540\t0.948866\n",
      "8\t0.029770\t0.978637\n",
      "9\t0.013231\t0.991868\n",
      "10\t0.005292\t0.997160\n",
      "11\t0.001925\t0.999085\n",
      "99.8% of probability mass covered by k≤11\n"
     ]
    }
   ],
   "source": [
    "analyze_poisson(4, \"rental2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analysis for return2 (lambda=2):\n",
      "k\tProb\tCumulative\n",
      "------------------------------\n",
      "0\t0.135335\t0.135335\n",
      "1\t0.270671\t0.406006\n",
      "2\t0.270671\t0.676676\n",
      "3\t0.180447\t0.857123\n",
      "4\t0.090224\t0.947347\n",
      "5\t0.036089\t0.983436\n",
      "6\t0.012030\t0.995466\n",
      "7\t0.003437\t0.998903\n",
      "99.8% of probability mass covered by k≤7\n"
     ]
    }
   ],
   "source": [
    "analyze_poisson(2, \"return2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building state class that uses tensors\n",
    "class TensorState(State):\n",
    "    # Poisson cutoffs for rentals and returns based on 99.9% of cumulative probability\n",
    "    RENTAL1_CUTOFF = 9  # lambda=3\n",
    "    RETURN1_CUTOFF = 9  # lambda=3\n",
    "    RENTAL2_CUTOFF = 11  # lambda=4\n",
    "    RETURN2_CUTOFF = 7   # lambda=2    \n",
    "    \n",
    "    def __init__(self):\n",
    "        # Initialize value function matrix. 0-20 cars at each location, so 21x21\n",
    "        self.V = np.zeros((21, 21), dtype=float)\n",
    "        \n",
    "        # Initialize policy as action for each state, so 21x21 again, with each value from [-5, 5]\n",
    "        self.policy = np.zeros((21, 21), dtype=int)\n",
    "        \n",
    "        # Initialize Q values as 21x21x11 (states x actions). 11 actions from -5 to 5\n",
    "        self.Q = np.zeros((21, 21, 11), dtype=float)\n",
    "        \n",
    "        # Compute Poisson probabilities for possible rental and return cutoffs\n",
    "        self.rental1_probs = poisson.pmf(k=np.arange(self.RENTAL1_CUTOFF + 1), mu=3)\n",
    "        self.return1_probs = poisson.pmf(k=np.arange(self.RETURN1_CUTOFF + 1), mu=3)\n",
    "        self.rental2_probs = poisson.pmf(k=np.arange(self.RENTAL2_CUTOFF + 1), mu=4)\n",
    "        self.return2_probs = poisson.pmf(k=np.arange(self.RETURN2_CUTOFF + 1), mu=2)\n",
    "        \n",
    "        # Action mask to mask out actions that cannot happen (21x21x11)\n",
    "        self.action_mask = self._initialize_action_mask()\n",
    "    \n",
    "    def _initialize_action_mask(self):\n",
    "        \"\"\"Initialize action mask based on valid car transfers\"\"\"\n",
    "        mask = np.zeros((21, 21, 11), dtype=bool)\n",
    "        \n",
    "        # Loop over possible cars at loc1\n",
    "        for i in range(21):\n",
    "            # Loop over possible cars at loc2\n",
    "            for j in range(21):\n",
    "                for a_idx, action in enumerate(range(-5, 6)):\n",
    "                    # Movement constraints\n",
    "                    valid = (action <= i) and (-action <= j)\n",
    "                    mask[i, j, a_idx] = valid\n",
    "\n",
    "        return mask\n",
    "    \n",
    "    def _action_idx_to_value(self, idx) -> int:\n",
    "        \"\"\"Converts action index to the action value\"\"\"\n",
    "        return idx - 5\n",
    "    \n",
    "    def get_post_action_states(self):\n",
    "        \"\"\"\n",
    "        Get states after making the action for all possible initial states and actions.\n",
    "        Returns:\n",
    "            post_states: (21, 21, 11, 2) tensor with last dim being [cars_loc1, cars_loc2]\n",
    "            move_rewards: (21, 21, 11) tensor of rewards for moving cars\n",
    "        \"\"\"\n",
    "        # Possible number of cars at a location\n",
    "        cars_at_loc = np.arange(21)\n",
    "        # Possible actions [-5, 5]\n",
    "        possible_actions = np.arange(-5, 6)\n",
    "        \n",
    "        # Meshgrid for states and actions\n",
    "        i, j, actions = np.meshgrid(cars_at_loc, cars_at_loc, possible_actions, indexing='ij')\n",
    "        \n",
    "        # New states after moving cars\n",
    "        post_loc1 = np.clip(i - actions, 0, 20)\n",
    "        post_loc2 = np.clip(j + actions, 0, 20)\n",
    "        \n",
    "        # Calculate rewards for movement\n",
    "        move_rewards = -2 * np.abs(actions)\n",
    "        \n",
    "        # Stack post_loc states into one array\n",
    "        post_states = np.stack([post_loc1, post_loc2], axis=-1)\n",
    "        \n",
    "        return post_states, move_rewards\n",
    "    \n",
    "    def get_rental_return_transitions(self, post_states):\n",
    "        \"\"\"\n",
    "        Compute transitions from rentals and returns for all states after car movements.\n",
    "        \n",
    "        Args:\n",
    "            post_states: (21, 21, 11, 2) tensor from get_post_action_states\n",
    "            \n",
    "        Returns:\n",
    "            - transition_probs: tensor containing probabilities for each combination\n",
    "            - rental_rewards: tensor containing rewards from rentals\n",
    "        \"\"\"\n",
    "        # Split post states into loc1 and loc 2\n",
    "        cars_loc1, cars_loc2 = post_states[..., 0], post_states[..., 1]\n",
    "        \n",
    "        # Possible returns and rentals at each location\n",
    "        possible_rentals1 = np.minimum(np.arange(self.RENTAL1_CUTOFF + 1)[:, None, None, None], cars_loc1)\n",
    "        possible_returns1 = np.arange(self.RETURN1_CUTOFF + 1)\n",
    "        possible_rentals2 = np.minimum(np.arange(self.RENTAL2_CUTOFF + 1)[:, None, None, None], cars_loc2)\n",
    "        possible_returns2 = np.arange(self.RETURN2_CUTOFF + 1)\n",
    "        \n",
    "        # Calculate probabilities for each combination with einsum\n",
    "        probs = np.einsum('i,j,k,l->ijkl',\n",
    "                          self.rental1_probs,\n",
    "                          self.return1_probs,\n",
    "                          self.rental2_probs,\n",
    "                          self.return2_probs,\n",
    "                          )\n",
    "        \n",
    "        return probs\n",
    "    \n",
    "    def create_transition_mask(self, post_states, location):\n",
    "        match location:\n",
    "            case 1:\n",
    "                loc = 0\n",
    "                rental_cutoff = self.RENTAL1_CUTOFF\n",
    "                return_cutoff = self.RETURN1_CUTOFF\n",
    "            case 2:\n",
    "                loc = 1\n",
    "                rental_cutoff = self.RENTAL2_CUTOFF\n",
    "                return_cutoff = self.RETURN2_CUTOFF\n",
    "        \n",
    "        # Split post states into loc1 and loc 2\n",
    "        cars = post_states[..., loc] # Shape: (21, 21, 11)\n",
    "        \n",
    "        # Reshape cars for broadcasting:\n",
    "        cars = cars.reshape(1, 1, 21, 21, 11)\n",
    "        \n",
    "        # Broadcast for loc1\n",
    "        rentals = np.arange(rental_cutoff + 1).reshape(-1, 1, 1, 1, 1)\n",
    "        returns = np.arange(return_cutoff + 1).reshape(1, -1, 1, 1, 1)\n",
    "        \n",
    "        mask = ((0 <= cars - rentals + returns) & (cars - rentals + returns <= 20))\n",
    "        \n",
    "        return mask\n",
    "    \n",
    "    def get_valid_transitions(self, post_states):\n",
    "        \"\"\"\n",
    "        Get valid transitions using a mask and their probabilities\n",
    "\n",
    "        Args:\n",
    "            post_states: (21, 21, 11, 2) tensor from get_post_action_states\n",
    "        \n",
    "        Returns:\n",
    "            valid_indices: indicies in the transitions matrix that are valid\n",
    "            probs: probabilities of the transitions matrix\n",
    "        \"\"\"\n",
    "        # Get basic action mask first\n",
    "        valid_mask = self.action_mask.reshape(1, 1, 1, 1, 21, 21, 11)\n",
    "        \n",
    "        # Apply location 1 constraints\n",
    "        mask1 = self.create_transition_mask(post_states, location=1)\n",
    "        valid_mask &= mask1.reshape(self.RENTAL1_CUTOFF + 1, self.RETURN1_CUTOFF + 1, 1, 1, 21, 21, 11)\n",
    "        \n",
    "        # Apply location 2 constraints\n",
    "        mask2 = self.create_transition_mask(post_states, location=2)\n",
    "        valid_mask &= mask2.reshape(1, 1, self.RENTAL2_CUTOFF + 1, self.RETURN2_CUTOFF + 1, 21, 21, 11)\n",
    "        \n",
    "        # Get indices where valid\n",
    "        valid_indices = np.where(valid_mask)\n",
    "        \n",
    "        # Calculate probabilities for valid transitions\n",
    "        rentals1, returns1, rentals2, returns2, i, j, a = valid_indices\n",
    "        probs = self.rental1_probs[rentals1] * self.return1_probs[returns1] * self.rental2_probs[rentals2] * self.return2_probs[returns2]\n",
    "        \n",
    "        return valid_indices, probs\n",
    "    \n",
    "    def calculate_rewards(self, valid_indices, move_rewards):\n",
    "        \"\"\"\n",
    "        Calculate rewards for valid transitions\n",
    "\n",
    "        Args:\n",
    "            valid_indices: tuple of (rentals1, returns1, rentals2, returns2, i, j, a) indices\n",
    "            move_rewards: (21, 21, 11) tensor of movement rewards from get_post_action_states\n",
    "\n",
    "        Returns:\n",
    "            total_reward: array of (rentals1, returns1, rentals2, returns2, i, j, a) rewards from valid transitions\n",
    "        \"\"\"\n",
    "        rentals1, returns1, rentals2, returns2, i, j, a = valid_indices\n",
    "        \n",
    "        # Movement rewards for valid transitions\n",
    "        movement_reward = move_rewards[i, j, a]\n",
    "        \n",
    "        # Rental rewards ($10 for each rental)\n",
    "        rental_reward = 10 * (rentals1 + rentals2)\n",
    "        \n",
    "        # Total reward\n",
    "        total_reward = movement_reward + rental_reward\n",
    "        \n",
    "        return total_reward\n",
    "    \n",
    "    def calculate_next_states(self, valid_indices, post_states):\n",
    "        \"\"\"\n",
    "        Calculate next states for valid transitions\n",
    "        \n",
    "        Args:\n",
    "            valid_indices: tuple of (rentals1, returns1, rentals2, returns2, i, j, a)\n",
    "            post_states: (21, 21, 11, 2) tensor from get_post_action_states\n",
    "            \n",
    "        Returns:\n",
    "            next_states: Array of shape (num_valid_transitions, 2) containing [next_cars1, next_cars2] for each valid transition\n",
    "        \"\"\"\n",
    "        rentals1, returns1, rentals2, returns2, i, j, a = valid_indices\n",
    "        \n",
    "        # Get post-action states for these indices\n",
    "        post_cars1 = post_states[i, j, a, 0]  # Cars at loc1 after moving\n",
    "        post_cars2 = post_states[i, j, a, 1]  # Cars at loc2 after moving\n",
    "        \n",
    "        # Calculate next states after rentals and returns\n",
    "        next_cars1 = post_cars1 - rentals1 + returns1\n",
    "        next_cars2 = post_cars2 - rentals2 + returns2\n",
    "        \n",
    "        # Stack into single array\n",
    "        next_states = np.stack([next_cars1, next_cars2], axis=1)\n",
    "        \n",
    "        return next_states\n",
    "    \n",
    "    def policy_evaluation(self, theta: float=0.01, gamma: float=0.9) -> None:\n",
    "        \"\"\"Policy Evaluation using vectorized operations\"\"\"\n",
    "        eval_iteration = 0\n",
    "        \n",
    "        while True:\n",
    "            delta = 0\n",
    "            old_V = self.V.copy()\n",
    "            \n",
    "            # Get states and rewards after we take our action\n",
    "            post_states, move_rewards = self.get_post_action_states()\n",
    "            \n",
    "            # Debug: Check move_rewards\n",
    "            print(\"Move rewards range:\", np.min(move_rewards), np.max(move_rewards))\n",
    "            \n",
    "            # Get valid transitions and probabilities\n",
    "            valid_indices, probs = self.get_valid_transitions(post_states)\n",
    "            \n",
    "            # Debug: Check probabilities\n",
    "            print(\"Probability sum:\", np.sum(probs))\n",
    "            print(\"Probability range:\", np.min(probs), np.max(probs))\n",
    "            \n",
    "            # Get rewards\n",
    "            total_rewards = self.calculate_rewards(valid_indices, move_rewards)\n",
    "            \n",
    "            # Debug: Check total rewards\n",
    "            print(\"Total rewards range:\", np.min(total_rewards), np.max(total_rewards))\n",
    "            \n",
    "            # Get next states\n",
    "            next_states = self.calculate_next_states(valid_indices, post_states)\n",
    "            \n",
    "            # Calculate next state values\n",
    "            next_state_values = self.V[next_states[:, 0], next_states[:, 1]]\n",
    "            \n",
    "            # Expected values for each transition\n",
    "            expected_values = probs * (total_rewards + gamma * next_state_values)\n",
    "            \n",
    "            # Debug: Check expected values\n",
    "            print(\"Expected values range:\", np.min(expected_values), np.max(expected_values))\n",
    "            \n",
    "            # Need to sum up values for each starting state (i, j)\n",
    "            i, j = valid_indices[4], valid_indices[5] # Starting indices\n",
    "            state_indices = i * 21 + j # Flatten indices\n",
    "            \n",
    "            # Sum values over each state and set back to V matrix\n",
    "            self.V = np.bincount(state_indices, \n",
    "                                 weights=expected_values, \n",
    "                                 minlength=21*21,\n",
    "                                 ).reshape(21, 21)\n",
    "            \n",
    "            # Calculate delta\n",
    "            delta = np.max(np.abs(old_V - self.V))\n",
    "            \n",
    "            eval_iteration += 1\n",
    "            print(f\"Policy Evaluation iteration {eval_iteration}, delta: {delta}\")\n",
    "            \n",
    "            if delta < theta:\n",
    "                break\n",
    "    \n",
    "    def policy_improvement(self, gamma: float=0.9):\n",
    "        \"\"\"Policy Improvement using vectorized operations\"\"\"\n",
    "        policy_stable = True\n",
    "        \n",
    "        # Set old actions\n",
    "        old_policy = self.policy.copy()\n",
    "        \n",
    "        # Get states and rewards after action is made\n",
    "        post_states, move_rewards = self.get_post_action_states()\n",
    "        \n",
    "        # Get valid transitions and probabilities\n",
    "        valid_indices, probs = self.get_valid_transitions(post_states)\n",
    "        \n",
    "        # Get rewards\n",
    "        total_rewards = self.calculate_rewards(valid_indices, move_rewards)\n",
    "        \n",
    "        # Get next states\n",
    "        next_states = self.calculate_next_states(valid_indices, post_states)\n",
    "        \n",
    "        # Calculate next state values\n",
    "        next_state_values = self.V[next_states[:, 0], next_states[:, 1]]\n",
    "        \n",
    "        # Action values for each transition\n",
    "        action_values = probs * (total_rewards + gamma * next_state_values)\n",
    "        \n",
    "        # Sum values for state-action pairs\n",
    "        i, j, a = valid_indices[4], valid_indices[5], valid_indices[6] # (s=(s1, s2), a)\n",
    "        state_action_indices = (i * 21 * 11) + (j * 11) + a # Flatten indices\n",
    "        Q = np.bincount(state_action_indices, \n",
    "                        weights=action_values, \n",
    "                        minlength=21*21*11,\n",
    "                        ).reshape(21, 21, 11)\n",
    "        \n",
    "        # Find best action for each states\n",
    "        self.policy = self._action_idx_to_value(np.argmax(Q, axis=2)) # Convert action index to action value\n",
    "        \n",
    "        # Check if policy-stable\n",
    "        policy_changes = np.sum(old_policy != self.policy)\n",
    "        policy_stable = (policy_changes == 0)\n",
    "        \n",
    "        print(f\"Number of policy changes: {policy_changes}\")\n",
    "\n",
    "        return policy_stable\n",
    "    \n",
    "    def visualize_iteration(self, iteration: int, save_figs: bool = False):\n",
    "        \"\"\"Visualize current value function and policy\"\"\"\n",
    "        plt.figure(figsize=(12, 5))\n",
    "        \n",
    "        # Plot values\n",
    "        plt.subplot(121)\n",
    "        plt.imshow(self.V, origin='lower')\n",
    "        plt.colorbar(label='Value')\n",
    "        plt.title(f'State Values (Iteration {iteration})')\n",
    "        plt.xlabel('Cars at Location 2')\n",
    "        plt.ylabel('Cars at Location 1')\n",
    "        plt.xticks(range(0, 21, 5))\n",
    "        plt.yticks(range(0, 21, 5))\n",
    "        \n",
    "        # Plot policy\n",
    "        plt.subplot(122)\n",
    "        plt.imshow(self.policy, origin='lower')\n",
    "        plt.colorbar(label='Action')\n",
    "        plt.title(f'Policy (Iteration {iteration})')\n",
    "        plt.xlabel('Cars at Location 2')\n",
    "        plt.ylabel('Cars at Location 1')\n",
    "        plt.xticks(range(0, 21, 5))\n",
    "        plt.yticks(range(0, 21, 5))\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        if save_figs:\n",
    "            plt.savefig(f'iteration_{iteration}.png')\n",
    "        plt.close()\n",
    "    \n",
    "    def display_all_iterations(self, num_iterations):\n",
    "        \"\"\"Display all saved iterations in a grid\"\"\"\n",
    "        # Calculate grid dimensions\n",
    "        grid_size = int(np.ceil(np.sqrt(num_iterations)))\n",
    "        \n",
    "        plt.figure(figsize=(4*grid_size, 4*grid_size))\n",
    "        for i in range(num_iterations):\n",
    "            plt.subplot(grid_size, grid_size, i+1)\n",
    "            img = plt.imread(f'iteration_{i+1}.png')\n",
    "            plt.imshow(img)\n",
    "            plt.axis('off')\n",
    "            plt.title(f'Iteration {i+1}')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def policy_iteration(self, theta: float=0.01, gamma: float=0.9):\n",
    "        \"\"\"Policy Iteration Algorithm using vectorized operations\"\"\"\n",
    "        iteration = 0\n",
    "        \n",
    "        while True:\n",
    "            iteration += 1\n",
    "            print(f\"\\nIteration {iteration}\")\n",
    "            \n",
    "            # Policy Evaluation\n",
    "            print(\"Policy Evaluation...\")\n",
    "            self.policy_evaluation(theta, gamma)\n",
    "            \n",
    "            # Policy Improvement\n",
    "            print(\"Policy Improvement...\")\n",
    "            policy_stable = self.policy_improvement(gamma)\n",
    "            \n",
    "            # Visualize and save current state\n",
    "            self.visualize_iteration(iteration)\n",
    "            \n",
    "            if policy_stable:\n",
    "                print(\"Policy stable!\")\n",
    "                break\n",
    "        \n",
    "        # Display all iterations at the end\n",
    "        self.display_all_iterations(iteration)\n",
    "        \n",
    "        return self.V, self.policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 1\n",
      "Policy Evaluation...\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 3460.451717175281\n",
      "Probability range: 1.0853976432428951e-12 0.002654299736637786\n",
      "Total rewards range: -10 210\n",
      "Expected values range: -0.0005529791117995389 0.18580098156464503\n",
      "Policy Evaluation iteration 1, delta: 702.6441790016019\n",
      "Move rewards range: -10 0\n",
      "Probability sum: 3460.451717175281\n",
      "Probability range: 1.0853976432428951e-12 0.002654299736637786\n",
      "Total rewards range: -10 210\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "original_problem = TensorState()\n",
    "original_problem.policy_iteration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
